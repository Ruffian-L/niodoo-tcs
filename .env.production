# ðŸ”¥ BEELINK PRODUCTION ENVIRONMENT - ALL REAL VALUES
# Generated: 2025-10-21
# No more asking - everything is here

# =============================================================================
# SERVER INFO
# =============================================================================
HOSTNAME=beelink
LOCAL_IP=10.42.104.23
TAILSCALE_IP=100.113.10.90
SSH_USER=beelink

# =============================================================================
# GPU & HARDWARE
# =============================================================================
GPU_NAME=NVIDIA RTX A6000
GPU_VRAM=48GB
GPU_DRIVER=570.172.08
GPU_ARCH=Ampere
GPU_COMPUTE_CAP=sm_75
CUDA_VISIBLE_DEVICES=0

# =============================================================================
# VLLM OPENAI-COMPATIBLE API (RUNNING)
# =============================================================================
VLLM_ENDPOINT=http://10.42.104.23:8000
VLLM_ENDPOINT_TAILSCALE=http://100.113.10.90:8000
VLLM_MODEL_ID=/home/beelink/models/Qwen2.5-7B-Instruct-AWQ
VLLM_MAX_CONTEXT=4096
VLLM_GPU_MEMORY_UTILIZATION=0.9
VLLM_QUANTIZATION=awq

# OpenAI-compatible endpoints:
# - GET  /v1/models
# - POST /v1/chat/completions
# - POST /v1/completions
# - POST /v1/embeddings

# =============================================================================
# QDRANT VECTOR DATABASE (RUNNING)
# =============================================================================
QDRANT_URL=http://10.42.104.23:6333
QDRANT_URL_TAILSCALE=http://100.113.10.90:6333
QDRANT_COLLECTION=experiences
QDRANT_VECTOR_SIZE=768
QDRANT_DISTANCE=Cosine
QDRANT_POINTS_COUNT=160

# =============================================================================
# MODEL PATHS (ALL ON DISK)
# =============================================================================
MODELS_DIR=/home/beelink/models

# Qwen Models
QWEN_7B_AWQ=/home/beelink/models/Qwen2.5-7B-Instruct-AWQ
QWEN_32B_AWQ=/home/beelink/models/Qwen2.5-32B-AWQ
QWEN_TOKENIZER=/home/beelink/models/Qwen2.5-7B-Instruct-AWQ/tokenizer.json

# Embedding Models
BERT_BASE=/home/beelink/models/bert-base-uncased
MINILM=/home/beelink/models/minilm
EMOTION_MODEL=/home/beelink/models/emotion_detection

# Other Models
DEEPSEEK_33B_AWQ=/home/beelink/models/deepseek-33b-awq
DEEPSEEK_33B_GGUF=/home/beelink/models/deepseek-33b-q4.gguf
QWEN_CODER_ONNX=/home/beelink/models/qwen2.5-coder-0.5b-instruct-onnx

# =============================================================================
# PROJECT PATHS
# =============================================================================
PROJECT_ROOT=/home/beelink/Niodoo-Final
BINARIES_DIR=/home/beelink/Niodoo-Final/target/release
LOGS_DIR=/home/beelink/Niodoo-Final/logs
DATA_DIR=/home/beelink/Niodoo-Final/data
CONFIG_DIR=/home/beelink/Niodoo-Final/config

# =============================================================================
# BUILT BINARIES (READY TO USE)
# =============================================================================
BIN_NIODOO_INTEGRATED=/home/beelink/Niodoo-Final/target/release/niodoo_real_integrated
BIN_LEARNING_DAEMON=/home/beelink/Niodoo-Final/target/release/learning_daemon
BIN_LEARNING_PIPELINE=/home/beelink/Niodoo-Final/target/release/learning_pipeline
BIN_CONTINUAL_TEST=/home/beelink/Niodoo-Final/target/release/continual_test
BIN_QWEN_TEST=/home/beelink/Niodoo-Final/target/release/real_qwen_test
BIN_WEBSOCKET_SERVER=/home/beelink/Niodoo-Final/target/release/niodoo-websocket-server
BIN_EMOTIONAL_INFLUENCE=/home/beelink/Niodoo-Final/target/release/emotional_influence

# =============================================================================
# OLLAMA (RUNNING BUT NOT USED)
# =============================================================================
OLLAMA_ENDPOINT=http://10.42.104.23:11434
OLLAMA_API_TAGS=http://10.42.104.23:11434/api/tags

# =============================================================================
# TESTING & BENCHMARKING
# =============================================================================
TEST_ENDPOINT_VLLM=http://localhost:8000/v1/chat/completions
TEST_ENDPOINT_QDRANT=http://localhost:6333/collections/experiences
TEST_MODEL_PATH=/home/beelink/models/Qwen2.5-7B-Instruct-AWQ

# =============================================================================
# BUILD CONFIGURATION
# =============================================================================
RUST_LOG=info
CARGO_TARGET_DIR=/home/beelink/Niodoo-Final/target
RUSTFLAGS="-C target-cpu=native"

# =============================================================================
# NETWORK ACCESS
# =============================================================================
# From laptop: ssh beelink@10.42.104.23
# From anywhere: ssh beelink@100.113.10.90 (Tailscale)
# vLLM API: curl http://10.42.104.23:8000/v1/models
# Qdrant API: curl http://10.42.104.23:6333/collections

# =============================================================================
# QUICK START EXAMPLES
# =============================================================================
# Test vLLM:
#   curl -X POST $VLLM_ENDPOINT/v1/chat/completions \
#     -H "Content-Type: application/json" \
#     -d '{"model":"","messages":[{"role":"user","content":"Hi"}]}'
#
# Test Qdrant:
#   curl $QDRANT_URL/collections/$QDRANT_COLLECTION
#
# Run integrated pipeline:
#   $BIN_NIODOO_INTEGRATED --help
#
# Build new binary:
#   cd $PROJECT_ROOT && cargo build --release --bin your_binary

# =============================================================================
# STATUS: ALL VERIFIED LIVE AS OF 2025-10-21
# =============================================================================
