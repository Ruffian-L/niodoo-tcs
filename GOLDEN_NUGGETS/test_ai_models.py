#!/usr/bin/env python3
"""
Test script to verify NiodO.o's AI models are working
"""

import os
import sys
from pathlib import Path

def test_models():
    """Test if our AI models are accessible and valid"""
    print("ğŸ§ ğŸ’– Testing NiodO.o AI Models...")
    print("=" * 40)
    
    # Check if we're in the right directory
    ai_models_dir = Path("ai_models")
    if not ai_models_dir.exists():
        print("âŒ ai_models directory not found!")
        return False
    
    # List all models
    models = list(ai_models_dir.glob("*.gguf"))
    if not models:
        print("âŒ No .gguf models found!")
        return False
    
    print(f"âœ… Found {len(models)} AI models:")
    total_size = 0
    
    for model in models:
        size_mb = model.stat().st_size / (1024 * 1024)
        total_size += size_mb
        print(f"   ğŸ“¦ {model.name}: {size_mb:.1f} MB")
    
    print(f"\nğŸ’¾ Total AI brain size: {total_size:.1f} MB")
    
    # Check if models are valid (not empty)
    valid_models = []
    for model in models:
        if model.stat().st_size > 1000000:  # > 1MB
            valid_models.append(model)
        else:
            print(f"âš ï¸  {model.name} seems too small, might be corrupted")
    
    print(f"\nğŸ¯ Valid models: {len(valid_models)}/{len(models)}")
    
    if len(valid_models) == len(models):
        print("ğŸ‰ All AI models are ready!")
        print("ğŸš€ NiodO.o can now think!")
        return True
    else:
        print("âš ï¸  Some models may have issues")
        return False

def test_python_env():
    """Test if Python environment can load AI libraries"""
    print("\nğŸ Testing Python Environment...")
    print("=" * 40)
    
    try:
        import torch
        print(f"âœ… PyTorch: {torch.__version__}")
    except ImportError:
        print("âŒ PyTorch not available")
        return False
    
    try:
        import transformers
        print(f"âœ… Transformers: {transformers.__version__}")
    except ImportError:
        print("âŒ Transformers not available")
        return False
    
    try:
        import llama_cpp
        print(f"âœ… llama-cpp-python: {llama_cpp.__version__}")
        return True
    except ImportError:
        print("âŒ llama-cpp-python not available")
        print("ğŸ’¡ This is needed to run the GGUF models")
        return False

def main():
    """Main test function"""
    print("ğŸ§ ğŸ’– NIODO.O AI MODEL TEST SUITE")
    print("=" * 50)
    
    # Test 1: Check models exist
    models_ok = test_models()
    
    # Test 2: Check Python environment
    python_ok = test_python_env()
    
    print("\n" + "=" * 50)
    print("ğŸ“Š TEST RESULTS:")
    print(f"   AI Models: {'âœ… READY' if models_ok else 'âŒ ISSUES'}")
    print(f"   Python Env: {'âœ… READY' if python_ok else 'âŒ ISSUES'}")
    
    if models_ok and python_ok:
        print("\nğŸ‰ SUCCESS! NiodO.o is ready to think!")
        print("ğŸš€ Next step: Start the AI brain with:")
        print("   cd core/backend/echomemoria")
        print("   source ../../../niodo_env/bin/activate")
        print("   python3 websocket_bridge.py --server --port 8768")
    else:
        print("\nâš ï¸  Some issues detected. Check the output above.")
    
    return models_ok and python_ok

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
