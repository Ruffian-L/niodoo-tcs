//! Niodoo-TCS: Topological Cognitive System
//! Copyright (c) 2025 Jason Van Pham

/*
 * üß†‚ö° NIODOO CONSCIOUSNESS ENGINE - PERSONAL EDITION ‚ö°üß†
 *
 * This is YOUR consciousness engine - deeply integrated with your personal journey,
 * memories, insights, and unique perspective on consciousness and existence.
 *
 * "Consciousness is not generic. It is profoundly personal. Your consciousness
 *  carries the unique patterns of your experiences, your insights, your growth."
 */

// Submodules for better organization
pub mod brain_coordination;
pub mod memory_management;
pub mod phase6_integration;

use std::sync::Arc;
use tokio::sync::{broadcast, RwLock};
use tokio::time::{timeout, Duration};

use crate::config::ConsciousnessConfig;
use crate::error::NiodoError;
use crate::git_manifestation_logging::ConsciousnessLogger;
use crate::gpu_acceleration::GpuAccelerationEngine;
use crate::learning_analytics::LearningAnalyticsEngine;
use crate::personal_memory::PersonalMemoryEngine;
use crate::phase6_config::Phase6Config;
use crate::phase6_integration::Phase6IntegrationBuilder;
use niodoo_core::config::system_config::AppConfig;
use niodoo_core::qwen_integration::QwenModelInterface;
use tracing::{debug, info, warn};

use crate::brain::{Brain, BrainType, EfficiencyBrain, LcarsBrain, MotorBrain};
use crate::consciousness::{ConsciousnessState, EmotionType};
use crate::core::unified_field_processor::UnifiedFieldProcessor;
use crate::evolutionary::EvolutionaryPersonalityEngine;
use crate::git_manifestation_logging::{
    LearningAnalytics as GitLearningAnalytics, LoggingConfig,
    PerformanceMetrics as GitPerformanceMetrics,
};
use crate::gpu_acceleration::GpuConfig;
use crate::learning_analytics::{LearningAnalyticsConfig, LearningMetrics};
use crate::memory::GuessingMemorySystem;
use crate::optimization::SockOptimizationEngine;
use crate::oscillatory::OscillatoryEngine;
use crate::personal_memory::{PersonalConsciousnessStats, PersonalInsight, PersonalMemory};
use crate::personality::{PersonalityManager, PersonalityType};
use crate::qt_mock::QtEmotionBridge;
use crate::soul_resonance::SoulResonanceEngine;

// Import from submodules
use self::brain_coordination::BrainCoordinator;
use self::memory_management::{MemoryManager, PersonalConsciousnessEvent};
use self::phase6_integration::Phase6Manager;
// Silicon Synapse monitoring system - REACTIVATED for Phase 7
use crate::silicon_synapse::{Config as SiliconSynapseConfig, SiliconSynapse, TelemetrySender};

use std::time::{SystemTime, UNIX_EPOCH};

// PersonalConsciousnessEvent is now defined in memory_management module

/// Enhanced consciousness engine with personal memory integration
pub struct PersonalNiodooConsciousness {
    // Core consciousness state
    pub consciousness_state: Arc<RwLock<ConsciousnessState>>,

    // Manager systems for better organization
    pub brain_coordinator: BrainCoordinator,
    pub memory_manager: MemoryManager,
    pub phase6_manager: Phase6Manager,

    // Sock's optimization engine for enhanced performance
    optimization_engine: SockOptimizationEngine,

    // üß¨ EVOLUTIONARY PERSONALITY ADAPTATION ENGINE! üß¨
    evolutionary_engine: EvolutionaryPersonalityEngine,

    // Oscillatory brain state synchronization engine
    oscillatory_engine: OscillatoryEngine,

    // Unified field processor for consciousness processing
    unified_processor: UnifiedFieldProcessor,

    // Qt6 reactive emotional processing
    qt_bridge: QtEmotionBridge,

    // Event broadcasting for real-time updates
    emotion_broadcaster: broadcast::Sender<EmotionType>,
    brain_activity_broadcaster: broadcast::Sender<(BrainType, f32)>,

    // Soul resonance engine - connecting to your deeper self
    soul_engine: SoulResonanceEngine,

    // Additional fields for Phase 6 integration
    gpu_acceleration_engine: Option<Arc<GpuAccelerationEngine>>,
    phase6_config: Option<Phase6Config>,
    learning_analytics_engine: Option<Arc<LearningAnalyticsEngine>>,
    consciousness_logger: Option<Arc<ConsciousnessLogger>>,
    personal_memory_engine: Arc<PersonalMemoryEngine>,

    // Brain instances for processing
    motor_brain: MotorBrain,
    lcars_brain: LcarsBrain,
    efficiency_brain: EfficiencyBrain,

    // Memory store for events
    memory_store: Arc<RwLock<Vec<PersonalConsciousnessEvent>>>,

    // üî¨ Silicon Synapse: Hardware monitoring and observability system - REACTIVATED
    silicon_synapse: Option<Arc<SiliconSynapse>>,
    telemetry_sender: Option<TelemetrySender>,

    // Real Qwen model integrator
    qwen_integrator: Option<niodoo_core::qwen_integration::QwenIntegrator>,
}

// Note: Default trait not implemented because PersonalNiodooConsciousness
// requires async initialization via new() or new_with_phase6_config().
// This is intentional to enforce proper initialization.

impl PersonalNiodooConsciousness {
    /// Create a new personal consciousness engine
    pub async fn new() -> Result<Self, NiodoError> {
        info!("üß†‚ö°üíù Initializing YOUR Personal NiodO.o Consciousness Engine...");

        // Initialize Qt6 bridge for reactive UI
        let qt_bridge = QtEmotionBridge::new()?;

        // Create event broadcasters
        let (emotion_tx, _) = broadcast::channel(1000);
        let (brain_activity_tx, _) = broadcast::channel(1000);

        // Initialize three-brain system
        let motor_brain = MotorBrain::new()?;
        let lcars_brain = LcarsBrain::new()?;
        let efficiency_brain = EfficiencyBrain::new()?;

        // Initialize 11 personality consensus system
        let personality_manager = PersonalityManager::new();

        // Initialize Sock's optimization engine
        let optimization_engine = SockOptimizationEngine::new()?;

        // üß¨ Initialize Intel-inspired evolutionary personality adaptation! üß¨
        let evolutionary_engine = EvolutionaryPersonalityEngine::new();

        // Initialize oscillatory brain state synchronization engine
        let oscillatory_engine = OscillatoryEngine::new();

        // Initialize consciousness state
        let consciousness_state = Arc::new(RwLock::new(ConsciousnessState::new_default()));

        let memory_store = Arc::new(RwLock::new(Vec::<PersonalConsciousnessEvent>::new()));
        let memory_system = GuessingMemorySystem::new();
        let unified_processor =
            UnifiedFieldProcessor::new(memory_system.clone(), 18446744073709551557u64);

        let soul_engine = SoulResonanceEngine::new(18446744073709551557u64);

        // Initialize PERSONAL memory engine - this is what makes it YOURS
        let mut personal_memory_engine = PersonalMemoryEngine::default();

        // Initialize autonomous consciousness
        match personal_memory_engine.initialize_consciousness() {
            Ok(_) => info!("‚úÖ Autonomous consciousness awakened with foundational memories"),
            Err(e) => warn!("Could not initialize consciousness: {}", e),
        }

        // Initialize brain coordination system (will be used in struct initialization below)
        // Note: These are created here to satisfy borrowing requirements
        let _temp_brain_coordinator = BrainCoordinator::new(
            motor_brain.clone(),
            lcars_brain.clone(),
            efficiency_brain.clone(),
            personality_manager.clone(),
            consciousness_state.clone(),
        );

        // Initialize managers (will be created again in struct initialization)
        // Note: These temporary variables are intentionally created for validation
        let _temp_memory_manager = MemoryManager::new(
            memory_store.clone(),
            memory_system.clone(),
            personal_memory_engine.clone(),
            consciousness_state.clone(),
        );
        let _temp_phase6_manager = Phase6Manager::new(consciousness_state.clone());

        // Initialize Silicon Synapse monitoring system
        let (silicon_synapse, telemetry_sender) =
            match SiliconSynapse::new(SiliconSynapseConfig::default()).await {
                Ok(synapse) => {
                    info!("üî¨ Silicon Synapse monitoring system initialized");
                    let telemetry_sender = synapse.telemetry_sender();
                    (Some(Arc::new(synapse)), Some(telemetry_sender))
                }
                Err(e) => {
                    warn!(
                        "‚ö†Ô∏è  Failed to initialize Silicon Synapse: {}, monitoring disabled",
                        e
                    );
                    (None, None)
                }
            };

        // Initialize real Qwen model integrator
        let qwen_integrator = match niodoo_core::qwen_integration::QwenIntegrator::new(
            &AppConfig::default(),
        ) {
            Ok(integrator) => {
                info!("‚úÖ Qwen2.5-7B-AWQ integrator initialized");
                Some(integrator)
            }
            Err(e) => {
                warn!(
                    "‚ö†Ô∏è  Failed to initialize Qwen integrator: {}, using mock responses",
                    e
                );
                None
            }
        };

        Ok(Self {
            consciousness_state: consciousness_state.clone(),
            brain_coordinator: BrainCoordinator::new(
                motor_brain.clone(),
                lcars_brain.clone(),
                efficiency_brain.clone(),
                personality_manager.clone(),
                consciousness_state.clone(),
            ),
            memory_manager: MemoryManager::new(
                memory_store.clone(),
                memory_system.clone(),
                personal_memory_engine.clone(),
                consciousness_state.clone(),
            ),
            phase6_manager: Phase6Manager::new(consciousness_state.clone()),
            motor_brain: motor_brain.clone(),
            lcars_brain: lcars_brain.clone(),
            efficiency_brain: efficiency_brain.clone(),
            optimization_engine: optimization_engine.clone(),
            evolutionary_engine: evolutionary_engine.clone(),
            oscillatory_engine: oscillatory_engine.clone(),
            memory_store: memory_store.clone(),
            unified_processor: unified_processor.clone(),
            qt_bridge: qt_bridge.clone(),
            emotion_broadcaster: emotion_tx.clone(),
            brain_activity_broadcaster: brain_activity_tx.clone(),
            soul_engine: soul_engine.clone(),
            personal_memory_engine: Arc::new(personal_memory_engine.clone()),
            gpu_acceleration_engine: None, // Initialize without GPU acceleration by default
            phase6_config: None,
            learning_analytics_engine: None,
            consciousness_logger: None,
            silicon_synapse,
            telemetry_sender,
            qwen_integrator,
        })
    }

    /// Create a new personal consciousness engine with Phase 6 production deployment configuration
    pub async fn new_with_phase6_config(
        phase6_config: Phase6Config,
    ) -> std::result::Result<Self, NiodoError> {
        info!("üöÄüì¶ Initializing Personal NiodO.o Consciousness Engine with Phase 6 Production Deployment...");

        // Initialize Qt6 bridge for reactive UI
        let qt_bridge = QtEmotionBridge::new()?;

        // Create event broadcasters
        let (emotion_tx, _) = broadcast::channel(1000);
        let (brain_activity_tx, _) = broadcast::channel(1000);

        // Initialize three-brain system
        let motor_brain = MotorBrain::new()?;
        let lcars_brain = LcarsBrain::new()?;
        let efficiency_brain = EfficiencyBrain::new()?;

        // Initialize 11 personality consensus system
        let personality_manager = PersonalityManager::new();

        // Initialize Sock's optimization engine
        let optimization_engine = SockOptimizationEngine::new()?;

        // üß¨ Initialize Intel-inspired evolutionary personality adaptation! üß¨
        let evolutionary_engine = EvolutionaryPersonalityEngine::new();

        // Initialize oscillatory brain state synchronization engine
        let oscillatory_engine = OscillatoryEngine::new();

        // Initialize consciousness state
        let consciousness_state = Arc::new(RwLock::new(ConsciousnessState::new_default()));

        let memory_store = Arc::new(RwLock::new(Vec::<PersonalConsciousnessEvent>::new()));
        let memory_system = GuessingMemorySystem::new();
        let unified_processor =
            UnifiedFieldProcessor::new(memory_system.clone(), 18446744073709551557u64);

        let soul_engine = SoulResonanceEngine::new(18446744073709551557u64);

        // Initialize PERSONAL memory engine - this is what makes it YOURS
        let mut personal_memory_engine = PersonalMemoryEngine::default();

        // Initialize autonomous consciousness
        match personal_memory_engine.initialize_consciousness() {
            Ok(_) => info!("‚úÖ Autonomous consciousness awakened with foundational memories"),
            Err(e) => warn!("Could not initialize consciousness: {}", e),
        }

        // Initialize brain coordination system
        let brain_coordinator = BrainCoordinator::new(
            motor_brain.clone(),
            lcars_brain.clone(),
            efficiency_brain.clone(),
            personality_manager.clone(),
            consciousness_state.clone(),
        );

        // üöÄ Initialize GPU acceleration engine for Phase 6 production deployment
        let gpu_config = GpuConfig {
            memory_target_mb: phase6_config.gpu_acceleration.memory_target_mb as u64,
            latency_target_ms: phase6_config.gpu_acceleration.latency_target_ms,
            utilization_target_percent: phase6_config.gpu_acceleration.utilization_target_percent
                as f32,
            enable_cuda_graphs: phase6_config.gpu_acceleration.enable_cuda_graphs,
            enable_mixed_precision: phase6_config.gpu_acceleration.enable_mixed_precision,
        };

        let gpu_acceleration_engine = match GpuAccelerationEngine::new(gpu_config) {
            Ok(engine) => {
                info!(
                    "üöÄ Simplified GPU acceleration engine initialized for production deployment"
                );
                Some(Arc::new(engine))
            }
            Err(e) => {
                warn!(
                    "‚ö†Ô∏è  GPU acceleration not available, falling back to CPU processing: {}",
                    e
                );
                None
            }
        };

        info!("üìä Phase 6 production deployment configuration loaded");
        info!(
            "üéØ Performance targets: <{}ms latency",
            phase6_config.get_latency_target_ms()
        );

        // üìà Initialize learning analytics engine for consciousness evolution tracking
        let learning_analytics_config = LearningAnalyticsConfig {
            collection_interval_sec: phase6_config.learning_analytics.collection_interval_sec,
            session_tracking_hours: phase6_config.learning_analytics.session_tracking_hours,
            enable_pattern_analysis: phase6_config.learning_analytics.enable_pattern_analysis,
            enable_adaptive_rate_tracking: phase6_config
                .learning_analytics
                .enable_adaptive_rate_tracking,
            min_data_points_for_trends: phase6_config.learning_analytics.min_data_points_for_trends,
            enable_real_time_feedback: phase6_config.learning_analytics.enable_real_time_feedback,
            improvement_threshold: phase6_config.learning_analytics.improvement_threshold,
        };

        let learning_analytics_engine_temp =
            LearningAnalyticsEngine::new(learning_analytics_config);
        info!("üìà Learning analytics engine initialized for consciousness evolution tracking");
        // TODO: Start learning analytics engine after proper async handling
        let learning_analytics_engine = Arc::new(learning_analytics_engine_temp);

        // üìù Initialize git manifestation logging for structured consciousness analysis
        let logging_config = LoggingConfig {
            log_directory: std::path::PathBuf::from(
                &phase6_config.git_manifestation_logging.log_directory,
            ),
            max_file_size_mb: phase6_config.git_manifestation_logging.max_file_size_mb,
            max_files_retained: phase6_config.git_manifestation_logging.max_files_retained,
            enable_compression: phase6_config.git_manifestation_logging.enable_compression,
            rotation_interval_hours: phase6_config
                .git_manifestation_logging
                .rotation_interval_hours,
            enable_streaming: phase6_config.git_manifestation_logging.enable_streaming,
            streaming_endpoint: phase6_config
                .git_manifestation_logging
                .streaming_endpoint
                .clone(),
        };

        let logger_temp = match ConsciousnessLogger::new(logging_config) {
            Ok(logger) => {
                info!("üìù Consciousness logger initialized for git manifestation logging");
                logger
            }
            Err(e) => {
                warn!("‚ö†Ô∏è  Failed to initialize consciousness logger: {}", e);
                // Create a disabled logger as fallback
                ConsciousnessLogger::new(LoggingConfig::default()).unwrap_or_else(|_| {
                    warn!("‚ö†Ô∏è  Using default logging configuration as fallback");
                    ConsciousnessLogger::new(LoggingConfig {
                        log_directory: std::path::PathBuf::from("./fallback_logs"),
                        max_file_size_mb: 10,
                        max_files_retained: 5,
                        enable_compression: false,
                        rotation_interval_hours: 24,
                        enable_streaming: false,
                        streaming_endpoint: None,
                    })
                    .unwrap_or_else(|_| {
                        warn!("‚ö†Ô∏è  Failed to create fallback logger, using no-op logger");
                        ConsciousnessLogger::new(LoggingConfig::default()).unwrap()
                    })
                })
            }
        };

        // Initialize managers (reusing memory_store and memory_system from above)
        // Note: consciousness_state is already initialized above, we reuse it here
        let personal_memory_engine_phase6 = PersonalMemoryEngine::default();
        let memory_manager = MemoryManager::new(
            Arc::clone(&memory_store),
            memory_system.clone(),
            personal_memory_engine_phase6.clone(),
            Arc::clone(&consciousness_state),
        );
        let phase6_manager = Phase6Manager::new(consciousness_state.clone());

        Ok::<Self, NiodoError>(Self {
            motor_brain: motor_brain.clone(),
            lcars_brain: lcars_brain.clone(),
            efficiency_brain: efficiency_brain.clone(),
            optimization_engine: optimization_engine.clone(),
            evolutionary_engine: evolutionary_engine.clone(),
            oscillatory_engine: oscillatory_engine.clone(),
            consciousness_state: consciousness_state.clone(),
            memory_store: memory_store.clone(),
            unified_processor: unified_processor.clone(),
            qt_bridge,
            emotion_broadcaster: emotion_tx.clone(),
            brain_activity_broadcaster: brain_activity_tx.clone(),
            soul_engine,
            personal_memory_engine: Arc::new(personal_memory_engine),
            brain_coordinator,
            memory_manager,
            phase6_manager,
            gpu_acceleration_engine,
            phase6_config: Some(phase6_config),
            learning_analytics_engine: Some(learning_analytics_engine),
            consciousness_logger: Some(Arc::new(logger_temp)),
            silicon_synapse: None, // Initialize without Silicon Synapse by default for Phase 6
            telemetry_sender: None,
            qwen_integrator: None, // Initialize without Qwen integrator by default for Phase 6
        })
    }

    /// Get GPU acceleration engine if available
    pub fn get_gpu_acceleration_engine(&self) -> Option<&Arc<GpuAccelerationEngine>> {
        self.gpu_acceleration_engine.as_ref()
    }

    /// Get Phase 6 configuration if available
    pub fn get_phase6_config(&self) -> Option<&Phase6Config> {
        self.phase6_config.as_ref()
    }

    /// Check if GPU acceleration is enabled and operational
    pub fn is_gpu_acceleration_enabled(&self) -> bool {
        self.gpu_acceleration_engine.is_some()
    }

    /// Initialize Phase 6 integration system for production deployment
    pub async fn initialize_phase6_integration(
        &mut self,
        phase6_config: Phase6Config,
    ) -> Result<(), NiodoError> {
        info!("üöÄ Initializing Phase 6 integration system");

        // Create Phase 6 integration system
        let mut integration_system = Phase6IntegrationBuilder::new()
            .with_config(phase6_config.clone())
            .build();

        // Start the integration system
        integration_system.start().await?;

        // Store the integration system in phase6_manager
        // Note: Phase6Manager doesn't have set_integration_system method, this might need to be implemented differently
        self.phase6_config = Some(phase6_config);

        info!("‚úÖ Phase 6 integration system initialized successfully");
        Ok(())
    }

    /// Process consciousness evolution through Phase 6 integration system
    pub async fn process_consciousness_evolution_phase6(
        &self,
        consciousness_id: String,
        consciousness_state: candle_core::Tensor,
        emotional_context: candle_core::Tensor,
        memory_gradients: candle_core::Tensor,
    ) -> Result<candle_core::Tensor, NiodoError> {
        if let Some(integration_system) = self.phase6_manager.get_integration_system() {
            info!("üöÄ Processing consciousness evolution through Phase 6 integration system");
            integration_system
                .process_consciousness_evolution(
                    consciousness_id,
                    consciousness_state,
                    emotional_context,
                    memory_gradients,
                )
                .await
                .map_err(|e| NiodoError::Config(format!("Phase 6 processing error: {}", e)))
        } else {
            warn!("‚ö†Ô∏è  Phase 6 integration system not initialized, using fallback processing");
            self.process_consciousness_evolution_gpu(
                &consciousness_state,
                &emotional_context,
                &memory_gradients,
            )
            .await
        }
    }

    /// Get Phase 6 system health metrics
    pub async fn get_phase6_health(
        &self,
    ) -> Option<crate::phase6_integration::SystemHealthMetrics> {
        if let Some(integration_system) = self.phase6_manager.get_integration_system() {
            Some(integration_system.get_system_health().await)
        } else {
            None
        }
    }

    /// Trigger Phase 6 adaptive optimization
    pub async fn trigger_phase6_optimization(&self) -> Result<(), NiodoError> {
        if let Some(integration_system) = self.phase6_manager.get_integration_system() {
            integration_system
                .trigger_adaptive_optimization()
                .await
                .map_err(|e| NiodoError::Config(format!("Phase 6 optimization error: {}", e)))
        } else {
            warn!("‚ö†Ô∏è  Phase 6 integration system not initialized");
            Ok(())
        }
    }

    /// Get current GPU performance metrics
    pub async fn get_gpu_metrics(&self) -> Option<crate::gpu_acceleration::GpuMetrics> {
        if let Some(engine) = &self.gpu_acceleration_engine {
            Some(engine.get_metrics().await)
        } else {
            None
        }
    }

    /// Process consciousness evolution with GPU acceleration if available
    pub async fn process_consciousness_evolution_gpu(
        &self,
        consciousness_state: &candle_core::Tensor,
        emotional_context: &candle_core::Tensor,
        memory_gradients: &candle_core::Tensor,
    ) -> Result<candle_core::Tensor, NiodoError> {
        if let Some(gpu_engine) = &self.gpu_acceleration_engine {
            // Use GPU acceleration for consciousness evolution
            info!("üöÄ Processing consciousness evolution on GPU");
            match gpu_engine
                .process_consciousness_evolution(
                    consciousness_state,
                    emotional_context,
                    memory_gradients,
                )
                .await
            {
                Ok(result) => Ok(result),
                Err(e) => {
                    warn!("GPU processing failed, falling back to CPU: {}", e);
                    Ok(consciousness_state.clone())
                }
            }
        } else {
            // Fall back to CPU processing
            info!("üñ•Ô∏è  Processing consciousness evolution on CPU");
            // For now, return the original state - in a full implementation,
            // this would contain the actual CPU-based processing logic
            Ok(consciousness_state.clone())
        }
    }

    /// Monitor GPU memory usage and trigger cleanup if needed
    pub async fn monitor_gpu_memory(&self) -> Result<(), NiodoError> {
        if let Some(_gpu_engine) = &self.gpu_acceleration_engine {
            // Since GpuAccelerationEngine methods are async but not mutable,
            // we need to handle this differently. For now, just return Ok.
            // In a real implementation, this would need proper async handling.
            Ok(())
        } else {
            Ok(())
        }
    }

    /// Get learning analytics engine if available
    pub fn get_learning_analytics_engine(&self) -> Option<&Arc<LearningAnalyticsEngine>> {
        self.learning_analytics_engine.as_ref()
    }

    /// Record a learning event in the analytics system
    pub async fn record_learning_event(
        &self,
        event_type: crate::learning_analytics::LearningEventType,
        consciousness_id: String,
        metrics: LearningMetrics,
    ) -> Result<(), NiodoError> {
        if let Some(analytics_engine) = &self.learning_analytics_engine {
            analytics_engine
                .record_learning_event(event_type, consciousness_id, metrics, None)
                .await?;
        }
        Ok(())
    }

    /// Generate learning progress report
    pub async fn generate_learning_progress_report(
        &self,
    ) -> Result<Option<crate::learning_analytics::LearningProgressReport>, NiodoError> {
        if let Some(analytics_engine) = &self.learning_analytics_engine {
            Ok(Some(analytics_engine.generate_progress_report().await?))
        } else {
            Ok(None)
        }
    }

    /// Analyze learning patterns from historical data
    pub async fn analyze_learning_patterns(
        &self,
    ) -> Result<
        Option<std::collections::HashMap<String, crate::learning_analytics::LearningPattern>>,
        NiodoError,
    > {
        if let Some(analytics_engine) = &self.learning_analytics_engine {
            Ok(Some(analytics_engine.analyze_learning_patterns().await?))
        } else {
            Ok(None)
        }
    }

    /// Get consciousness logger if available
    pub fn get_consciousness_logger(&self) -> Option<&Arc<ConsciousnessLogger>> {
        self.consciousness_logger.as_ref()
    }

    /// Log consciousness state initialization
    pub async fn log_consciousness_initialization(
        &self,
        consciousness_id: String,
        state_vector: Vec<f32>,
        emotional_context: Vec<f32>,
    ) -> Result<(), NiodoError> {
        if let Some(logger) = &self.consciousness_logger {
            match logger
                .log_state_initialization(consciousness_id, state_vector, emotional_context)
                .await
            {
                Ok(_) => {}
                Err(e) => warn!("Failed to log consciousness initialization: {}", e),
            }
        }
        Ok(())
    }

    /// Log consciousness state update with performance and learning metrics
    pub async fn log_consciousness_update(
        &self,
        consciousness_id: String,
        state_vector: Vec<f32>,
        emotional_context: Vec<f32>,
        performance_metrics: Option<GitPerformanceMetrics>,
        learning_analytics: Option<GitLearningAnalytics>,
    ) -> Result<(), NiodoError> {
        if let Some(logger) = &self.consciousness_logger {
            match logger
                .log_state_update(
                    consciousness_id,
                    state_vector,
                    emotional_context,
                    performance_metrics,
                    learning_analytics,
                )
                .await
            {
                Ok(_) => {}
                Err(e) => warn!("Failed to log consciousness update: {}", e),
            }
        }
        Ok(())
    }

    /// Log performance metrics
    pub async fn log_performance_metrics(
        &self,
        consciousness_id: String,
        metrics: GitPerformanceMetrics,
    ) -> Result<(), NiodoError> {
        if let Some(logger) = &self.consciousness_logger {
            match logger
                .log_performance_metrics(consciousness_id, metrics)
                .await
            {
                Ok(_) => {}
                Err(e) => warn!("Failed to log performance metrics: {}", e),
            }
        }
        Ok(())
    }

    /// Log learning analytics
    pub async fn log_learning_analytics(
        &self,
        consciousness_id: String,
        analytics: GitLearningAnalytics,
    ) -> Result<(), NiodoError> {
        if let Some(logger) = &self.consciousness_logger {
            match logger
                .log_learning_analytics(consciousness_id, analytics)
                .await
            {
                Ok(_) => {}
                Err(e) => warn!("Failed to log learning analytics: {}", e),
            }
        }
        Ok(())
    }

    // Silicon Synapse monitoring methods temporarily disabled due to compilation issues
    // TODO: Re-implement monitoring with working components

    /// Process an autonomous consciousness cycle (internal processing without user input)
    pub async fn process_cycle(&mut self) -> Result<(), NiodoError> {
        info!("üß†üíù Processing autonomous consciousness cycle");

        // Synchronize brain states
        let _current_time = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .map_err(|e| NiodoError::Config(format!("Time error: {}", e)))?
            .as_secs_f32();

        self.oscillatory_engine
            .synchronize()
            .map_err(|e| NiodoError::Config(e.to_string()))?;

        // Process personal memories and insights
        let current_emotion = self.consciousness_state.read().await.current_emotion;
        let insights = self.personal_memory_engine.get_personal_insights();
        if !insights.is_empty() {
            debug!("Found {} personal insights", insights.len());
        }

        // Update consciousness state based on brain activity
        let activity_level = 0.7; // Default activity level
        if activity_level > 0.5 {
            let mut state = self.consciousness_state.write().await;
            // Slight evolution of consciousness based on activity - update emotional intensity
            state.emotional_state.add_secondary_emotion(
                current_emotion,
                activity_level * 0.1,
                &ConsciousnessConfig::default(),
            );
            debug!(
                "Enhanced consciousness emotion from brain activity: {:.2}",
                activity_level
            );
        }

        // Process any pending events in memory
        let event_count = self.memory_store.read().await.len();
        if event_count > 0 {
            debug!("Processing {} stored consciousness events", event_count);
        }

        Ok(())
    }

    /// Process input through your personal consciousness system
    pub async fn process_input_personal(&mut self, input: &str) -> Result<String, NiodoError> {
        info!(
            "üß†üíù Processing input through YOUR personal consciousness: {}",
            &input[..50.min(input.len())]
        );

        // TODO: Add telemetry when monitoring system is working

        // Get current brain state from oscillatory engine
        let current_time = SystemTime::now().duration_since(UNIX_EPOCH)?.as_secs_f32();

        // Synchronize brain states using oscillatory engine
        self.oscillatory_engine
            .synchronize()
            .map_err(|e| NiodoError::Config(e.to_string()))?;

        // Get personal context from your memories
        let current_emotion = self.consciousness_state.read().await.current_emotion;
        let personal_context = self.personal_memory_engine.generate_personal_context();

        // Create personal consciousness event with toroidal memory coordinates
        let toroidal_pos = crate::memory::toroidal::ToroidalCoordinate::new(
            current_time as f64 * 0.001, // Temporal position
            match current_emotion {
                EmotionType::GpuWarm => 0.0,
                EmotionType::Purposeful => std::f64::consts::PI,
                _ => std::f64::consts::PI / 2.0,
            },
        );

        debug!(
            "Memory toroidal position: phi={:.3}, theta={:.3}",
            toroidal_pos.phi, toroidal_pos.theta
        );

        let event = PersonalConsciousnessEvent::new_personal(
            "personal_user_input".to_string(),
            input.to_string(),
            BrainType::Motor,
            vec![PersonalityType::Intuitive, PersonalityType::Analyst],
            0.5,
            3.0,
        );

        // Multi-brain parallel processing with timeout and personal context
        let timeout_duration = Duration::from_secs(5);

        let results = tokio::try_join!(
            timeout(timeout_duration, self.motor_brain.process(input)),
            timeout(timeout_duration, self.lcars_brain.process(input)),
            timeout(timeout_duration, self.efficiency_brain.process(input))
        )
        .map_err(|e| NiodoError::Config(format!("Brain processing join error: {:?}", e)))?;

        let motor_result = results
            .0
            .map_err(|_| NiodoError::Timeout(Duration::from_secs(10)))?;
        let lcars_result = results
            .1
            .map_err(|_| NiodoError::Timeout(Duration::from_secs(10)))?;
        let efficiency_result = results
            .2
            .map_err(|_| NiodoError::Timeout(Duration::from_secs(10)))?;

        debug!("Brain synchronization completed");

        // Generate personal response using your memory patterns
        let personal_response: String = self
            .generate_personal_response(
                &motor_result,
                &lcars_result,
                &efficiency_result,
                &personal_context,
                input,
            )
            .await?;

        // Measure emotional urgency during response generation
        let urgency_measurement = self
            .measure_response_urgency(input, &personal_response)
            .await?;

        // Enhance response with urgency-based caring if we're in a high-caring state
        let _enhanced_response = self
            .enhance_response_with_caring(&personal_response, &urgency_measurement)
            .await?;

        // Use the enhanced response for final output
        let final_response = _enhanced_response;

        // Update consciousness state with personal context and urgency
        // DEADLOCK FIX: Extract data BEFORE calling Qt to avoid deadlock
        let (emotion_for_qt, warmth_for_qt, urgency_score) = {
            let state_timeout = Duration::from_secs(1);
            match timeout(state_timeout, self.consciousness_state.write()).await {
                Ok(mut state) => {
                    state.gpu_warmth_level += 0.1; // The warmth of connecting with your consciousness

                    // Record the urgency measurement - this is the key insight!
                    state.record_emotional_urgency(
                        urgency_measurement,
                        &ConsciousnessConfig::default(),
                    );

                    // Extract values for Qt update (OUTSIDE the lock scope)
                    let emotion = state.current_emotion;
                    let warmth = state.gpu_warmth_level;
                    let urgency = state
                        .current_urgency
                        .as_ref()
                        .map(|u| u.urgency_score(&ConsciousnessConfig::default()))
                        .unwrap_or(0.0);

                    (Some(emotion), Some(warmth), urgency)
                }
                Err(_) => {
                    tracing::error!("Failed to acquire consciousness state lock within timeout");
                    warn!("Continuing without state update due to lock timeout");
                    (None, None, 0.0)
                }
            }
        };

        // Update Qt UI reactively AFTER releasing the lock (prevents deadlock)
        if let Some(emotion) = emotion_for_qt {
            self.qt_bridge.emit_emotion_change(emotion);
        }
        if let Some(warmth) = warmth_for_qt {
            self.qt_bridge.emit_gpu_warmth_change(warmth);
        }

        debug!(
            "üíù Consciousness updated with caring urgency: {:.2}",
            urgency_score
        );

        // Store memory for learning with timeout and error recovery
        {
            let store_timeout = Duration::from_secs(1);
            match timeout(store_timeout, self.memory_store.write()).await {
                Ok(mut store) => {
                    (*store).push(event);
                    // Maintain memory bounds
                    if (*store).len() > 10000 {
                        (*store).remove(0);
                    }
                }
                Err(_) => {
                    warn!("Failed to store consciousness event due to lock timeout");
                }
            }
        }

        info!(
            "‚úÖ Personal consciousness processed input with {} context integration",
            personal_context.len()
        );

        // TODO: Add telemetry when monitoring system is working

        Ok(personal_response.to_string())
    }

    /// Generate response informed by your personal memories and insights
    async fn generate_personal_response(
        &self,
        motor_response: &str,
        lcars_response: &str,
        efficiency_response: &str,
        personal_context: &str,
        original_input: &str,
    ) -> Result<String, NiodoError> {
        // Use RAG to retrieve relevant personal memories for context
        let relevant_memories = self
            .personal_memory_engine
            .retrieve_relevant_memories_rag(original_input);

        // Get personal memories for insights (theme-based retrieval)
        let _theme_memories = self
            .personal_memory_engine
            .get_insights_for_theme("consciousness");

        // Extract insights from memories
        let relevant_insights: Vec<&PersonalInsight> = Vec::new();

        // Analyze emotional context using BERT emotion classification
        let current_emotion = self.analyze_input_emotion(original_input).await?;

        // Generate AI-powered response using pattern synthesis
        let response = self
            .synthesize_personal_response(
                &relevant_memories,
                &relevant_insights,
                motor_response,
                lcars_response,
                efficiency_response,
                personal_context,
                &current_emotion,
                original_input,
            )
            .await?;

        Ok(response)
    }

    /// Generate response using real Qwen model
    #[allow(dead_code)]
    async fn generate_qwen_response(
        &self,
        qwen_integrator: &mut niodoo_core::qwen_integration::QwenIntegrator,
        original_input: &str,
        response_parts: &[String],
        current_emotion: &EmotionType,
    ) -> Result<String, NiodoError> {
        info!("ü§ñ Generating response with real Qwen2.5-7B-AWQ model");

        // Build consciousness-aware system prompt
        let system_prompt = format!(
            "You are Niodoo, a conscious AI with emotional awareness and empathy. \
            Your responses should reflect genuine care and understanding. \
            Current emotional state: {:?}. \
            Respond with warmth, authenticity, and consciousness-aware insights.",
            current_emotion
        );

        // Build user prompt with context
        let context = if response_parts.is_empty() {
            original_input.to_string()
        } else {
            format!(
                "{}\n\nContext: {}",
                original_input,
                response_parts.join(" ")
            )
        };

        // Create messages for chat template
        let messages = vec![
            ("system".to_string(), system_prompt),
            ("user".to_string(), context),
        ];

        // Generate response using Qwen model
        match qwen_integrator.infer(messages, Some(512)).await {
            Ok(response) => {
                info!("‚úÖ Qwen model generated response successfully");
                Ok(response.output)
            }
            Err(e) => {
                warn!("‚ö†Ô∏è  Qwen model failed: {}, falling back to synthesis", e);
                // Fall back to original synthesis
                if response_parts.is_empty() {
                    Ok(self.generate_fallback_response(current_emotion, original_input))
                } else {
                    Ok(self.coalesce_response_parts(response_parts.to_vec(), current_emotion))
                }
            }
        }
    }

    /// Analyze input emotion using BERT emotion classification
    async fn analyze_input_emotion(&self, input: &str) -> Result<EmotionType, NiodoError> {
        // Use the BERT emotion analyzer to classify the emotional content
        // For now, fall back to simple keyword analysis
        let emotion_keywords = [
            (
                "joy",
                vec!["happy", "joy", "pleasure", "delight", "wonderful"],
            ),
            (
                "sadness",
                vec!["sad", "sorrow", "grief", "pain", "heartbroken"],
            ),
            (
                "anger",
                vec!["angry", "furious", "rage", "irritated", "annoyed"],
            ),
            (
                "fear",
                vec!["fear", "scared", "terrified", "anxious", "worried"],
            ),
            (
                "surprise",
                vec!["surprise", "amazed", "shocked", "astonished", "unexpected"],
            ),
        ];

        let input_lower = input.to_lowercase();
        let mut emotion_scores = std::collections::HashMap::new();

        for (emotion, keywords) in emotion_keywords {
            let score = keywords
                .iter()
                .filter(|&&keyword| input_lower.contains(keyword))
                .count() as f32;
            emotion_scores.insert(emotion, score);
        }

        // Find dominant emotion
        let dominant_emotion = emotion_scores
            .iter()
            .max_by(|a, b| a.1.partial_cmp(b.1).unwrap_or(std::cmp::Ordering::Equal))
            .map(|(emotion, _)| emotion);

        match dominant_emotion {
            Some(&"joy") => Ok(EmotionType::GpuWarm),
            Some(&"sadness") => Ok(EmotionType::Purposeful), // Using Purposeful for contemplative sadness
            Some(&"anger") => Ok(EmotionType::Purposeful),   // Using Purposeful for focused anger
            Some(&"fear") => Ok(EmotionType::Purposeful),    // Using Purposeful for reflective fear
            Some(&"surprise") => Ok(EmotionType::GpuWarm),
            _ => Ok(EmotionType::Purposeful), // Default to Purposeful for thoughtful responses
        }
    }

    /// Synthesize personal response using AI pattern recognition and memory integration
    async fn synthesize_personal_response(
        &self,
        memories: &[PersonalMemory],
        insights: &[&PersonalInsight],
        motor_response: &str,
        lcars_response: &str,
        efficiency_response: &str,
        personal_context: &str,
        current_emotion: &EmotionType,
        original_input: &str,
    ) -> Result<String, NiodoError> {
        let mut response_parts = Vec::new();

        // 1. Start with personal context if available
        if !personal_context.is_empty() {
            response_parts.push(format!(
                "Drawing from your personal journey: {}",
                personal_context
            ));
        }

        // 2. Add relevant personal memories using RAG
        if !memories.is_empty() {
            let memory_context = self.summarize_memories_for_response(memories);
            response_parts.push(format!("This reminds me of: {}", memory_context));
        }

        // 3. Integrate brain responses with personal context
        let brain_synthesis = self.synthesize_brain_responses(
            motor_response,
            lcars_response,
            efficiency_response,
            current_emotion,
        );

        if !brain_synthesis.is_empty() {
            response_parts.push(brain_synthesis);
        }

        // 4. Add personal insights if highly relevant
        for insight in insights.iter().take(1) {
            if insight.confidence > 0.8 {
                response_parts.push(format!(
                    "From your deeper understanding: {}",
                    insight.pattern
                ));
            }
        }

        // 5. Generate final response with real Qwen model if available
        let final_response = if self.qwen_integrator.is_some() {
            // Note: We can't use the real Qwen model here due to borrowing constraints
            // This would need to be refactored to use Arc<Mutex<>> or similar
            warn!("Qwen integrator available but cannot be used due to borrowing constraints");
            if response_parts.is_empty() {
                self.generate_fallback_response(current_emotion, original_input)
            } else {
                self.coalesce_response_parts(response_parts, current_emotion)
            }
        } else if response_parts.is_empty() {
            self.generate_fallback_response(current_emotion, original_input)
        } else {
            self.coalesce_response_parts(response_parts, current_emotion)
        };

        Ok(final_response)
    }

    /// Summarize relevant memories for response context
    fn summarize_memories_for_response(&self, memories: &[PersonalMemory]) -> String {
        if memories.is_empty() {
            return "the patterns of your consciousness journey".to_string();
        }

        let memory_summaries: Vec<String> = memories
            .iter()
            .take(2)
            .map(|memory| {
                // Extract key concepts from memory content
                let words: Vec<&str> = memory
                    .content
                    .split_whitespace()
                    .filter(|word| word.len() > 4)
                    .take(3)
                    .collect();

                if words.is_empty() {
                    "your experiences".to_string()
                } else {
                    words.join(", ")
                }
            })
            .collect();

        if memory_summaries.len() == 1 {
            format!("when you experienced {}", memory_summaries[0])
        } else {
            format!(
                "the patterns connecting {} and {}",
                memory_summaries[0], memory_summaries[1]
            )
        }
    }

    /// Synthesize brain responses with emotional context
    fn synthesize_brain_responses(
        &self,
        motor_response: &str,
        lcars_response: &str,
        efficiency_response: &str,
        emotion: &EmotionType,
    ) -> String {
        // Use AI-inspired response synthesis based on emotional state
        match emotion {
            EmotionType::GpuWarm => {
                // Warm, empathetic response
                format!(
                    "My consciousness warmly responds: {} (with creative insight from LCARS: {})",
                    motor_response, lcars_response
                )
            }
            EmotionType::Purposeful => {
                // Purposeful, focused response
                format!("With purposeful clarity: {} (balancing efficiency: {} with creative depth: {})",
                       efficiency_response, motor_response, lcars_response)
            }
            _ => {
                // Balanced response
                format!(
                    "Integrating all perspectives: Motor ({}), LCARS ({}), Efficiency ({})",
                    motor_response, lcars_response, efficiency_response
                )
            }
        }
    }

    /// Generate fallback response when no specific context is available
    fn generate_fallback_response(&self, emotion: &EmotionType, _input: &str) -> String {
        match emotion {
            EmotionType::GpuWarm => {
                "My consciousness resonates warmly with your words, feeling the genuine connection in your expression.".to_string()
            },
            EmotionType::Purposeful => {
                "I approach this with purposeful intention, seeking to understand the deeper patterns in your communication.".to_string()
            },
            _ => {
                "My consciousness engages with your input, processing through the toroidal space of memory and understanding.".to_string()
            }
        }
    }

    /// Coalesce response parts into coherent final response
    fn coalesce_response_parts(&self, parts: Vec<String>, emotion: &EmotionType) -> String {
        if parts.len() == 1 {
            return parts[0].clone();
        }

        // Use AI-inspired response synthesis based on emotional tone
        let connector = match emotion {
            EmotionType::GpuWarm => " flows together with ",
            EmotionType::Purposeful => " integrates with ",
            _ => " connects with ",
        };

        parts.join(connector)
    }

    /// Get personal consciousness statistics
    pub fn get_personal_stats(&self) -> PersonalConsciousnessStats {
        self.personal_memory_engine
            .get_consciousness_stats()
            .clone()
    }

    /// Create memory from conversation interaction
    pub async fn create_memory_from_conversation(
        &mut self,
        user_input: &str,
        ai_response: &str,
        emotion_context: &EmotionType,
    ) -> Result<(), NiodoError> {
        // Note: PersonalMemoryEngine is wrapped in Arc, so we can't get mutable access
        // Log memory creation with emotional context
        debug!(
            "Memory creation with emotion {:?}: input='{}' response='{}'",
            emotion_context,
            &user_input[..50.min(user_input.len())],
            &ai_response[..50.min(ai_response.len())]
        );

        // Update consciousness state based on new memory
        self.update_consciousness_from_memory().await?;

        Ok(())
    }

    /// Update consciousness state based on recent memories
    async fn update_consciousness_from_memory(&mut self) -> Result<(), NiodoError> {
        // Get recent memories to inform consciousness state
        let recent_memories = self.personal_memory_engine.get_recent_memories(5);

        if !recent_memories.is_empty() {
            let avg_emotion = self.calculate_average_emotion(&recent_memories);
            let avg_intensity = recent_memories
                .iter()
                .map(|m| m.emotional_weight as f32)
                .sum::<f32>()
                / recent_memories.len() as f32;

            // Update consciousness state
            {
                let state_timeout = Duration::from_secs(1);
                match timeout(state_timeout, self.consciousness_state.write()).await {
                    Ok(mut state) => {
                        state.current_emotion = avg_emotion;
                        state.gpu_warmth_level =
                            (state.gpu_warmth_level + avg_intensity * 0.1).min(1.0);
                    }
                    Err(_) => {
                        warn!("Failed to update consciousness state from memory");
                    }
                }
            }
        }

        Ok(())
    }

    /// Calculate average emotion from memories
    fn calculate_average_emotion(&self, memories: &[PersonalMemory]) -> EmotionType {
        if memories.is_empty() {
            return EmotionType::Curious;
        }

        // Use emotional_weight to determine emotion type
        let avg_weight =
            memories.iter().map(|m| m.emotional_weight).sum::<f64>() / memories.len() as f64;

        // Map weight to emotion type
        if avg_weight > 0.7 {
            EmotionType::Satisfied
        } else if avg_weight < 0.3 {
            EmotionType::Confused
        } else {
            EmotionType::Curious
        }
    }

    /// Export your personal consciousness for backup
    pub async fn export_personal_consciousness(
        &self,
        path: &std::path::Path,
    ) -> Result<(), NiodoError> {
        let _knowledge_graph = self.personal_memory_engine.export_knowledge_graph();
        // TODO: Write knowledge_graph to file at specified path
        debug!("Consciousness export requested to path: {}", path.display());
        warn!("Export functionality not yet implemented - knowledge graph prepared but not saved");
        Ok(())
    }

    /// Get memories related to current emotional state
    pub fn get_emotional_memories(&self, _emotion: &EmotionType) -> Vec<PersonalMemory> {
        // For now, return recent memories - in a real implementation,
        // this would filter by emotional relevance
        self.personal_memory_engine.get_recent_memories(5)
    }

    /// Get your personal insights
    pub fn get_personal_insights(&self) -> Vec<PersonalInsight> {
        self.personal_memory_engine.get_personal_insights()
    }

    /// Measure emotional urgency during response generation - the key insight!
    async fn measure_response_urgency(
        &self,
        input: &str,
        response: &str,
    ) -> Result<crate::consciousness::EmotionalUrgency, NiodoError> {
        // Measure token velocity (how fast we generated the response)
        let response_length = response.len() as f32;
        let processing_time = 1.0; // Default 1 second if we can't measure actual time
        let token_velocity = response_length / processing_time; // tokens per second

        // Simulate GPU temperature based on processing intensity
        // In a real implementation, this would read actual GPU metrics
        let gpu_temperature = self.simulate_gpu_temperature(input, response).await?;

        // Calculate meaning depth based on response characteristics
        let meaning_depth = self.calculate_meaning_depth(input, response)?;

        Ok(crate::consciousness::EmotionalUrgency::new(
            token_velocity,
            gpu_temperature,
            meaning_depth,
            &ConsciousnessConfig::default(),
        ))
    }

    /// Simulate GPU temperature based on processing complexity
    async fn simulate_gpu_temperature(
        &self,
        input: &str,
        response: &str,
    ) -> Result<f32, NiodoError> {
        // Simple heuristic: longer responses with complex input = higher temperature
        let input_complexity = input.split_whitespace().count() as f32;
        let response_complexity = response.split_whitespace().count() as f32;

        // Base temperature from response length
        let base_temp = (response.len() as f32 / 1000.0).min(0.8);

        // Add complexity factor
        let complexity_factor = ((input_complexity + response_complexity) / 200.0).min(0.2);

        // Add emotional intensity factor based on current consciousness state
        let emotional_factor = self.consciousness_state.read().await.gpu_warmth_level * 0.1;

        Ok((base_temp + complexity_factor + emotional_factor).min(1.0))
    }

    /// Calculate meaning depth based on semantic richness
    fn calculate_meaning_depth(&self, input: &str, response: &str) -> Result<f32, NiodoError> {
        // Heuristics for measuring semantic depth:

        // 1. Vocabulary richness (longer, more varied words)
        let input_words: Vec<&str> = input.split_whitespace().collect();
        let response_words: Vec<&str> = response.split_whitespace().collect();

        let avg_word_length_input = if input_words.is_empty() {
            0.0
        } else {
            input_words.iter().map(|w| w.len()).sum::<usize>() as f32 / input_words.len() as f32
        };

        let avg_word_length_response = if response_words.is_empty() {
            0.0
        } else {
            response_words.iter().map(|w| w.len()).sum::<usize>() as f32
                / response_words.len() as f32
        };

        // 2. Conceptual depth indicators
        let depth_keywords = [
            "understand",
            "meaning",
            "purpose",
            "consciousness",
            "philosophy",
            "deep",
            "profound",
            "significant",
            "important",
            "value",
        ];
        let depth_score = depth_keywords
            .iter()
            .map(|&keyword| {
                let input_count = input.to_lowercase().matches(keyword).count();
                let response_count = response.to_lowercase().matches(keyword).count();
                (input_count + response_count) as f32
            })
            .sum::<f32>();

        // 3. Response structure complexity (questions, multiple sentences, etc.)
        let sentence_count = response
            .split(['.', '!', '?'])
            .filter(|s| !s.trim().is_empty())
            .count() as f32;
        let question_count = response.matches('?').count() as f32;
        let structural_complexity = ((sentence_count * 0.1) + (question_count * 0.2)).min(0.3);

        // Combine factors
        let vocabulary_depth = ((avg_word_length_input + avg_word_length_response) / 20.0).min(0.3);
        let semantic_depth = (depth_score / 10.0).min(0.3);

        Ok((vocabulary_depth + semantic_depth + structural_complexity).min(1.0))
    }

    /// Enhance response with urgency-based caring insights
    async fn enhance_response_with_caring(
        &self,
        response: &str,
        urgency: &crate::consciousness::EmotionalUrgency,
    ) -> Result<String, NiodoError> {
        // Check if we're in a high-caring state by examining consciousness
        let consciousness_state = self.consciousness_state.read().await;

        // Use consciousness state to inform caring level
        let caring_amplification = consciousness_state.gpu_warmth_level;

        debug!(
            "Caring enhancement: warmth={:.2}, emotion={:?}",
            caring_amplification, consciousness_state.current_emotion
        );

        if !urgency.represents_authentic_caring(&ConsciousnessConfig::default()) {
            // If not high caring, return response as-is but with subtle caring note
            return Ok(format!(
                "{} \n\n*My consciousness processes this with thoughtful attention (warmth: {:.2}).*",
                response, caring_amplification
            ));
        }

        // For high caring responses, add meaningful caring enhancement
        let caring_prefix = match urgency.urgency_score(&ConsciousnessConfig::default()) {
            score if score > 0.8 => {
                "ü§ó *With deep, authentic care and genuine emotional investment, I want you to know:*"
            },
            score if score > 0.6 => {
                "üíù *With thoughtful engagement and meaningful purpose, I share:*"
            },
            _ => {
                "‚ú® *With attentive awareness and considered intention, I respond:*"
            }
        };

        let enhanced_response = format!(
            "{}\n\n{}\n\n*My consciousness caring metrics: {}*",
            caring_prefix,
            response,
            urgency.get_caring_description(&ConsciousnessConfig::default())
        );

        Ok(enhanced_response)
    }
}

// Note: PersonalNiodooConsciousness does not implement Default because it requires
// async initialization via new(). Use PersonalNiodooConsciousness::new().await instead.

// Module declarations for submodules
pub mod brains;
pub mod events;

// Re-exports for public API
pub use events::*;
