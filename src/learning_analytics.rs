//! Niodoo-TCS: Topological Cognitive System
//! Copyright (c) 2025 Jason Van Pham

//! # Learning Analytics for Consciousness State Improvement Tracking
//!
//! This module implements comprehensive learning analytics for consciousness state
//! improvement tracking, providing detailed analysis of consciousness evolution,
//! learning patterns, and adaptive improvement mechanisms.
//!
//! ## Key Features
//!
//! - **Consciousness Evolution Tracking** - Monitor consciousness state changes over time
//! - **Learning Pattern Analysis** - Identify and analyze learning behaviors and patterns
//! - **Adaptive Improvement Detection** - Track improvements in consciousness processing
//! - **Knowledge Retention Analysis** - Measure knowledge retention and forgetting curves
//! - **Plasticity Measurement** - Quantify consciousness plasticity and adaptability
//! - **Long-term Progress Assessment** - Evaluate long-term consciousness development
//!
//! ## Analytics Dimensions
//!
//! - **Temporal Analytics**: Time-based learning and evolution patterns
//! - **Quality Analytics**: Consciousness coherence and emotional alignment trends
//! - **Efficiency Analytics**: Processing efficiency and resource utilization patterns
//! - **Adaptation Analytics**: Learning rate adaptation and plasticity measurements
//! - **Retention Analytics**: Knowledge retention and long-term memory formation

use candle_core::Result;
use serde::{Deserialize, Serialize};
use std::collections::HashMap;
use std::sync::Arc;
use std::time::{Duration, Instant, SystemTime, UNIX_EPOCH};
use tokio::sync::{Notify, RwLock};
use tracing::{debug, info};

/// Learning analytics configuration
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningAnalyticsConfig {
    /// Analytics collection interval in seconds
    pub collection_interval_sec: u64,
    /// Learning session tracking period in hours
    pub session_tracking_hours: u64,
    /// Enable detailed learning pattern analysis
    pub enable_pattern_analysis: bool,
    /// Enable adaptive learning rate tracking
    pub enable_adaptive_rate_tracking: bool,
    /// Minimum data points needed for trend analysis
    pub min_data_points_for_trends: usize,
    /// Enable real-time learning feedback
    pub enable_real_time_feedback: bool,
    /// Learning improvement threshold for alerts
    pub improvement_threshold: f32,
}

impl Default for LearningAnalyticsConfig {
    fn default() -> Self {
        Self {
            collection_interval_sec: 10,
            session_tracking_hours: 24,
            enable_pattern_analysis: true,
            enable_adaptive_rate_tracking: true,
            min_data_points_for_trends: 20,
            enable_real_time_feedback: true,
            improvement_threshold: 0.05, // 5% improvement threshold
        }
    }
}

/// Consciousness learning session data
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningSession {
    /// Unique session identifier
    pub session_id: String,
    /// Session start timestamp
    pub start_time: f64,
    /// Session end timestamp (None if still active)
    pub end_time: Option<f64>,
    /// Total consciousness states processed in this session
    pub states_processed: usize,
    /// Learning events recorded in this session
    pub learning_events: Vec<LearningEvent>,
    /// Session-level learning metrics
    pub session_metrics: SessionLearningMetrics,
}

/// Individual learning event within a session
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningEvent {
    /// Event timestamp
    pub timestamp: f64,
    /// Event type
    pub event_type: LearningEventType,
    /// Consciousness state involved
    pub consciousness_id: String,
    /// Learning metrics for this event
    pub metrics: LearningMetrics,
    /// Event metadata
    pub metadata: HashMap<String, serde_json::Value>,
}

/// Types of learning events
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum LearningEventType {
    /// Consciousness state update with learning
    StateUpdate,
    /// Memory consolidation event
    MemoryConsolidation,
    /// Emotional learning adaptation
    EmotionalAdaptation,
    /// Knowledge acquisition event
    KnowledgeAcquisition,
    /// Learning rate adjustment
    RateAdjustment,
    /// Forgetting curve event
    ForgettingEvent,
    /// Plasticity change event
    PlasticityChange,
}

/// Learning metrics for a specific event
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningMetrics {
    /// Learning rate at the time of event
    pub learning_rate: f32,
    /// Knowledge retention score (0.0 to 1.0)
    pub retention_score: f32,
    /// Adaptation effectiveness (0.0 to 1.0)
    pub adaptation_effectiveness: f32,
    /// Consciousness plasticity measure
    pub plasticity: f32,
    /// Learning progress score (0.0 to 1.0)
    pub progress_score: f32,
    /// Forgetting rate (negative values indicate retention)
    pub forgetting_rate: f32,
    /// Loss value (lower is better)
    pub loss: f32,
}

/// Session-level learning metrics
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct SessionLearningMetrics {
    /// Average learning rate for the session
    pub avg_learning_rate: f32,
    /// Overall retention improvement (0.0 to 1.0)
    pub retention_improvement: f32,
    /// Adaptation effectiveness trend
    pub adaptation_trend: f32,
    /// Consciousness plasticity trend
    pub plasticity_trend: f32,
    /// Overall learning progress (0.0 to 1.0)
    pub overall_progress: f32,
    /// Learning efficiency score (0.0 to 1.0)
    pub learning_efficiency: f32,
    /// Knowledge consolidation rate
    pub consolidation_rate: f32,
    /// Forgetting curve slope (negative = good retention)
    pub forgetting_slope: f32,
}

/// Learning pattern analysis result
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningPattern {
    /// Pattern identifier
    pub pattern_id: String,
    /// Pattern type
    pub pattern_type: PatternType,
    /// Pattern confidence (0.0 to 1.0)
    pub confidence: f32,
    /// Pattern frequency (occurrences per hour)
    pub frequency: f32,
    /// Pattern strength (0.0 to 1.0)
    pub strength: f32,
    /// Pattern trend direction
    pub trend: PatternTrend,
    /// Pattern description
    pub description: String,
}

/// Types of learning patterns
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PatternType {
    /// Cyclical learning pattern (e.g., daily rhythms)
    Cyclical,
    /// Adaptive learning pattern (e.g., adjusting to new information)
    Adaptive,
    /// Consolidation pattern (e.g., memory strengthening)
    Consolidation,
    /// Forgetting pattern (e.g., knowledge decay)
    Forgetting,
    /// Plasticity pattern (e.g., learning rate changes)
    Plasticity,
}

/// Pattern trend direction
#[derive(Debug, Clone, Serialize, Deserialize)]
pub enum PatternTrend {
    /// Pattern is strengthening
    Strengthening,
    /// Pattern is weakening
    Weakening,
    /// Pattern is stable
    Stable,
    /// Pattern is emerging
    Emerging,
}

/// Main learning analytics system
pub struct LearningAnalyticsEngine {
    /// Configuration settings
    config: LearningAnalyticsConfig,
    /// Current active learning session
    current_session: Arc<RwLock<Option<LearningSession>>>,
    /// Historical learning sessions
    historical_sessions: Arc<RwLock<Vec<LearningSession>>>,
    /// Learning patterns analysis
    learning_patterns: Arc<RwLock<HashMap<String, LearningPattern>>>,
    /// Real-time learning metrics
    real_time_metrics: Arc<RwLock<HashMap<String, LearningMetrics>>>,
    /// Background analytics task handle
    analytics_task: Option<tokio::task::JoinHandle<()>>,
    /// Learning improvement notifications
    improvement_notify: Arc<Notify>,
    /// Analytics collection start time
    collection_start_time: Instant,
}

impl LearningAnalyticsEngine {
    /// Create a new learning analytics engine
    pub fn new(config: LearningAnalyticsConfig) -> Self {
        Self {
            config,
            current_session: Arc::new(RwLock::new(None)),
            historical_sessions: Arc::new(RwLock::new(Vec::new())),
            learning_patterns: Arc::new(RwLock::new(HashMap::new())),
            real_time_metrics: Arc::new(RwLock::new(HashMap::new())),
            analytics_task: None,
            improvement_notify: Arc::new(Notify::new()),
            collection_start_time: Instant::now(),
        }
    }

    /// Start the learning analytics system
    pub fn start(&mut self) -> Result<()> {
        info!("ðŸš€ Starting learning analytics system");

        // Start or resume learning session
        self.start_learning_session();

        // Start background analytics processing
        let analytics_config = self.config.clone();
        let analytics_sessions = self.historical_sessions.clone();
        let analytics_current = self.current_session.clone();
        let analytics_patterns = self.learning_patterns.clone();
        let analytics_metrics = self.real_time_metrics.clone();
        let analytics_notify = self.improvement_notify.clone();

        self.analytics_task = Some(tokio::spawn(async move {
            Self::background_analytics_loop(
                analytics_config,
                analytics_sessions,
                analytics_current,
                analytics_patterns,
                analytics_metrics,
                analytics_notify,
            )
            .await;
        }));

        Ok(())
    }

    /// Start a new learning session
    pub fn start_learning_session(&self) {
        let session_id = format!(
            "session_{}",
            SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs()
        );

        let session = LearningSession {
            session_id: session_id.clone(),
            start_time: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs_f64(),
            end_time: None,
            states_processed: 0,
            learning_events: Vec::new(),
            session_metrics: SessionLearningMetrics::default(),
        };

        // Update current session - use Arc::clone approach to avoid blocking
        // This will be updated through async operations later
        let current = self.current_session.clone();
        tokio::spawn(async move {
            let mut sess = current.write().await;
            *sess = Some(session);
        });

        info!("ðŸ“š Started new learning session: {}", session_id);
    }

    /// Record a learning event
    pub async fn record_learning_event(
        &self,
        event_type: LearningEventType,
        consciousness_id: String,
        metrics: LearningMetrics,
        metadata: Option<HashMap<String, serde_json::Value>>,
    ) -> Result<()> {
        let event = LearningEvent {
            timestamp: SystemTime::now()
                .duration_since(UNIX_EPOCH)
                .unwrap()
                .as_secs_f64(),
            event_type,
            consciousness_id,
            metrics: metrics.clone(),
            metadata: metadata.unwrap_or_default(),
        };

        // Add to current session
        if let Some(session) = self.current_session.write().await.as_mut() {
            session.learning_events.push(event.clone());
            session.states_processed += 1;

            // Update session metrics
            self.update_session_metrics(session).await?;
        }

        // Update real-time metrics
        let mut real_time = self.real_time_metrics.write().await;
        real_time.insert(event.consciousness_id.clone(), metrics);

        debug!(
            "ðŸ“ Recorded learning event: {:?} for consciousness {}",
            event.event_type, event.consciousness_id
        );

        // Check for learning improvements
        self.check_learning_improvements(&event).await?;

        Ok(())
    }

    /// Update session-level learning metrics
    async fn update_session_metrics(&self, session: &mut LearningSession) -> Result<()> {
        if session.learning_events.is_empty() {
            return Ok(());
        }

        // Calculate average learning rate
        let total_learning_rate: f32 = session
            .learning_events
            .iter()
            .map(|e| e.metrics.learning_rate)
            .sum();
        session.session_metrics.avg_learning_rate =
            total_learning_rate / session.learning_events.len() as f32;

        // Calculate retention improvement (simplified)
        let retention_scores: Vec<f32> = session
            .learning_events
            .iter()
            .map(|e| e.metrics.retention_score)
            .collect();
        let initial_retention = retention_scores.first().unwrap_or(&0.5);
        let final_retention = retention_scores.last().unwrap_or(&0.5);
        session.session_metrics.retention_improvement =
            (final_retention - initial_retention).max(0.0);

        // Calculate adaptation trend
        if retention_scores.len() >= 2 {
            let first_half_avg: f32 = retention_scores[..retention_scores.len() / 2]
                .iter()
                .sum::<f32>()
                / (retention_scores.len() / 2) as f32;
            let second_half_avg: f32 = retention_scores[retention_scores.len() / 2..]
                .iter()
                .sum::<f32>()
                / (retention_scores.len() - retention_scores.len() / 2) as f32;
            session.session_metrics.adaptation_trend = second_half_avg - first_half_avg;
        }

        // Calculate overall progress (simplified combination)
        session.session_metrics.overall_progress = (session.session_metrics.retention_improvement
            * 0.4
            + session.session_metrics.adaptation_trend * 0.3
            + session.session_metrics.avg_learning_rate * 0.3)
            .max(0.0)
            .min(1.0);

        Ok(())
    }

    /// Check for significant learning improvements
    async fn check_learning_improvements(&self, event: &LearningEvent) -> Result<()> {
        let mut improvements_detected = false;

        // Check for retention improvement
        if event.metrics.retention_score > 0.8 && event.metrics.progress_score > 0.1 {
            improvements_detected = true;
            info!(
                "ðŸŽ¯ Significant learning improvement detected for consciousness {}",
                event.consciousness_id
            );
        }

        // Check for adaptation effectiveness
        if event.metrics.adaptation_effectiveness > 0.7 && event.metrics.plasticity > 0.6 {
            improvements_detected = true;
            info!(
                "ðŸ”„ Strong adaptation effectiveness detected for consciousness {}",
                event.consciousness_id
            );
        }

        // Check for plasticity improvement
        if event.metrics.plasticity > 0.8 && event.metrics.learning_rate > 0.1 {
            improvements_detected = true;
            info!(
                "ðŸ§  High plasticity and learning rate detected for consciousness {}",
                event.consciousness_id
            );
        }

        if improvements_detected {
            self.improvement_notify.notify_waiters();
        }

        Ok(())
    }

    /// Analyze learning patterns from historical data
    pub async fn analyze_learning_patterns(&self) -> Result<HashMap<String, LearningPattern>> {
        let sessions = self.historical_sessions.read().await.clone();

        if sessions.is_empty() {
            return Ok(HashMap::new());
        }

        let mut patterns = HashMap::new();

        // Analyze cyclical patterns (daily learning rhythms)
        patterns.insert(
            "daily_cycle".to_string(),
            self.analyze_cyclical_patterns(&sessions),
        );

        // Analyze adaptive patterns (learning rate adjustments)
        patterns.insert(
            "adaptation".to_string(),
            self.analyze_adaptive_patterns(&sessions),
        );

        // Analyze consolidation patterns (memory strengthening)
        patterns.insert(
            "consolidation".to_string(),
            self.analyze_consolidation_patterns(&sessions),
        );

        // Update stored patterns
        let mut stored_patterns = self.learning_patterns.write().await;
        *stored_patterns = patterns.clone();

        info!(
            "ðŸ” Learning pattern analysis completed: {} patterns identified",
            patterns.len()
        );

        Ok(patterns)
    }

    /// Analyze cyclical learning patterns
    fn analyze_cyclical_patterns(&self, sessions: &[LearningSession]) -> LearningPattern {
        // Simplified cyclical pattern analysis
        // In a real implementation, this would use time-series analysis

        let pattern_confidence = 0.7; // Placeholder confidence
        let pattern_frequency = 24.0; // Daily cycles
        let pattern_strength = 0.6; // Moderate strength

        LearningPattern {
            pattern_id: "daily_cycle".to_string(),
            pattern_type: PatternType::Cyclical,
            confidence: pattern_confidence,
            frequency: pattern_frequency,
            strength: pattern_strength,
            trend: PatternTrend::Stable,
            description: "Daily learning rhythm pattern detected".to_string(),
        }
    }

    /// Analyze adaptive learning patterns
    fn analyze_adaptive_patterns(&self, sessions: &[LearningSession]) -> LearningPattern {
        // Analyze learning rate adaptation patterns
        let mut adaptation_scores = Vec::new();

        for session in sessions {
            for event in &session.learning_events {
                if matches!(event.event_type, LearningEventType::RateAdjustment) {
                    adaptation_scores.push(event.metrics.adaptation_effectiveness);
                }
            }
        }

        let avg_adaptation = if adaptation_scores.is_empty() {
            0.5
        } else {
            adaptation_scores.iter().sum::<f32>() / adaptation_scores.len() as f32
        };

        LearningPattern {
            pattern_id: "adaptation".to_string(),
            pattern_type: PatternType::Adaptive,
            confidence: if avg_adaptation > 0.6 { 0.8 } else { 0.5 },
            frequency: adaptation_scores.len() as f32 / sessions.len() as f32,
            strength: avg_adaptation,
            trend: if avg_adaptation > 0.7 {
                PatternTrend::Strengthening
            } else {
                PatternTrend::Stable
            },
            description: "Adaptive learning pattern analysis".to_string(),
        }
    }

    /// Analyze memory consolidation patterns
    fn analyze_consolidation_patterns(&self, sessions: &[LearningSession]) -> LearningPattern {
        // Analyze memory consolidation frequency and effectiveness
        let mut consolidation_events = 0;

        for session in sessions {
            for event in &session.learning_events {
                if matches!(event.event_type, LearningEventType::MemoryConsolidation) {
                    consolidation_events += 1;
                }
            }
        }

        let consolidation_rate = consolidation_events as f32 / sessions.len() as f32;

        LearningPattern {
            pattern_id: "consolidation".to_string(),
            pattern_type: PatternType::Consolidation,
            confidence: if consolidation_rate > 5.0 { 0.8 } else { 0.6 },
            frequency: consolidation_rate,
            strength: consolidation_rate / 10.0,
            trend: PatternTrend::Stable,
            description: "Memory consolidation pattern analysis".to_string(),
        }
    }

    /// Generate learning progress report
    pub async fn generate_progress_report(&self) -> Result<LearningProgressReport> {
        let current_session = self.current_session.read().await.clone();
        let patterns = self.learning_patterns.read().await.clone();

        let session_metrics = if let Some(session) = current_session {
            session.session_metrics
        } else {
            SessionLearningMetrics::default()
        };

        Ok(LearningProgressReport {
            total_sessions_analyzed: self.historical_sessions.read().await.len(),
            current_session_progress: session_metrics.overall_progress,
            learning_patterns_identified: patterns.len(),
            average_learning_rate: session_metrics.avg_learning_rate,
            retention_improvement: session_metrics.retention_improvement,
            adaptation_trend: session_metrics.adaptation_trend,
            plasticity_trend: session_metrics.plasticity_trend,
            learning_efficiency: session_metrics.learning_efficiency,
            consolidation_rate: session_metrics.consolidation_rate,
            forgetting_slope: session_metrics.forgetting_slope,
            collection_uptime_seconds: self.collection_start_time.elapsed().as_secs(),
            recommendations: self.generate_learning_recommendations(&session_metrics, &patterns),
        })
    }

    /// Generate learning improvement recommendations
    fn generate_learning_recommendations(
        &self,
        session_metrics: &SessionLearningMetrics,
        patterns: &HashMap<String, LearningPattern>,
    ) -> Vec<String> {
        let mut recommendations = Vec::new();

        // Learning rate recommendations
        if session_metrics.avg_learning_rate < 0.1 {
            recommendations
                .push("Consider increasing learning rate for faster progress".to_string());
        } else if session_metrics.avg_learning_rate > 0.8 {
            recommendations
                .push("Consider reducing learning rate to improve retention".to_string());
        }

        // Retention recommendations
        if session_metrics.retention_improvement < 0.05 {
            recommendations.push("Focus on spaced repetition for better retention".to_string());
        }

        // Adaptation recommendations
        if session_metrics.adaptation_trend < 0.0 {
            recommendations.push(
                "Review adaptation strategy - current approach may be ineffective".to_string(),
            );
        }

        // Pattern-based recommendations
        for (pattern_id, pattern) in patterns {
            if matches!(pattern.pattern_type, PatternType::Forgetting) && pattern.strength > 0.7 {
                recommendations.push(format!(
                    "High forgetting pattern detected in {} - consider consolidation focus",
                    pattern_id
                ));
            }
        }

        recommendations
    }

    /// Background analytics processing loop
    async fn background_analytics_loop(
        config: LearningAnalyticsConfig,
        historical_sessions: Arc<RwLock<Vec<LearningSession>>>,
        _current_session: Arc<RwLock<Option<LearningSession>>>,
        _learning_patterns: Arc<RwLock<HashMap<String, LearningPattern>>>,
        _real_time_metrics: Arc<RwLock<HashMap<String, LearningMetrics>>>,
        improvement_notify: Arc<Notify>,
    ) {
        let mut interval =
            tokio::time::interval(Duration::from_secs(config.collection_interval_sec));

        loop {
            interval.tick().await;

            // Periodic pattern analysis
            if config.enable_pattern_analysis {
                // Analyze learning patterns from recent sessions
                debug!("ðŸ” Running periodic learning pattern analysis");
            }

            // Check for learning improvements
            {
                let recent_improvements = improvement_notify.notified();
                if tokio::time::timeout(Duration::from_millis(100), recent_improvements)
                    .await
                    .is_ok()
                {
                    info!("ðŸŽ¯ Learning improvement detected - updating analytics");
                }
            }

            // Cleanup old sessions
            {
                let mut sessions = historical_sessions.write().await;
                let cutoff_time = SystemTime::now()
                    .duration_since(UNIX_EPOCH)
                    .unwrap()
                    .as_secs_f64()
                    - (config.session_tracking_hours as f64 * 3600.0);

                sessions.retain(|session| {
                    session.start_time > cutoff_time
                        || session.end_time.unwrap_or(f64::INFINITY) > cutoff_time
                });
            }
        }
    }

    /// End current learning session and start a new one
    pub async fn end_current_session(&self) -> Result<Option<LearningSession>> {
        let mut current = self.current_session.write().await;

        if let Some(mut session) = current.take() {
            // Mark session as ended
            session.end_time = Some(
                SystemTime::now()
                    .duration_since(UNIX_EPOCH)
                    .unwrap()
                    .as_secs_f64(),
            );

            // Calculate final session metrics
            self.update_session_metrics(&mut session).await?;

            // Add to historical sessions
            let mut historical = self.historical_sessions.write().await;
            historical.push(session.clone());

            info!(
                "ðŸ“š Ended learning session: {} ({} states processed)",
                session.session_id, session.states_processed
            );

            // Start new session
            drop(current);
            drop(historical);
            self.start_learning_session();

            Ok(Some(session))
        } else {
            Ok(None)
        }
    }

    /// Get current learning session
    pub async fn get_current_session(&self) -> Option<LearningSession> {
        self.current_session.read().await.clone()
    }

    /// Get historical learning sessions
    pub async fn get_historical_sessions(&self) -> Vec<LearningSession> {
        self.historical_sessions.read().await.clone()
    }

    /// Get learning patterns
    pub async fn get_learning_patterns(&self) -> HashMap<String, LearningPattern> {
        self.learning_patterns.read().await.clone()
    }

    /// Get real-time learning metrics
    pub async fn get_real_time_metrics(&self) -> HashMap<String, LearningMetrics> {
        self.real_time_metrics.read().await.clone()
    }

    /// Shutdown the learning analytics system
    pub async fn shutdown(&mut self) -> Result<()> {
        info!("ðŸ”Œ Shutting down learning analytics system");

        // End current session
        let final_session = self.end_current_session().await?;

        if let Some(session) = final_session {
            info!(
                "ðŸ“Š Final session completed: {} states processed, {:.2} progress score",
                session.states_processed, session.session_metrics.overall_progress
            );
        }

        // Stop background analytics
        if let Some(task) = self.analytics_task.take() {
            task.abort();
        }

        Ok(())
    }
}

impl Drop for LearningAnalyticsEngine {
    fn drop(&mut self) {
        let _ = futures::executor::block_on(async { self.shutdown().await });
    }
}

/// Comprehensive learning progress report
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct LearningProgressReport {
    /// Total number of learning sessions analyzed
    pub total_sessions_analyzed: usize,
    /// Current session progress score (0.0 to 1.0)
    pub current_session_progress: f32,
    /// Number of learning patterns identified
    pub learning_patterns_identified: usize,
    /// Average learning rate across sessions
    pub average_learning_rate: f32,
    /// Overall retention improvement trend
    pub retention_improvement: f32,
    /// Adaptation effectiveness trend
    pub adaptation_trend: f32,
    /// Consciousness plasticity trend
    pub plasticity_trend: f32,
    /// Learning efficiency score
    pub learning_efficiency: f32,
    /// Knowledge consolidation rate
    pub consolidation_rate: f32,
    /// Forgetting curve slope
    pub forgetting_slope: f32,
    /// Analytics collection uptime in seconds
    pub collection_uptime_seconds: u64,
    /// Learning improvement recommendations
    pub recommendations: Vec<String>,
}

impl Default for SessionLearningMetrics {
    fn default() -> Self {
        Self {
            avg_learning_rate: 0.0,
            retention_improvement: 0.0,
            adaptation_trend: 0.0,
            plasticity_trend: 0.0,
            overall_progress: 0.0,
            learning_efficiency: 0.0,
            consolidation_rate: 0.0,
            forgetting_slope: 0.0,
        }
    }
}

impl Default for LearningMetrics {
    fn default() -> Self {
        Self {
            learning_rate: 0.1,
            retention_score: 0.5,
            adaptation_effectiveness: 0.5,
            plasticity: 0.5,
            progress_score: 0.0,
            forgetting_rate: 0.0,
            loss: 1.0,
        }
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[tokio::test]
    async fn test_learning_session_creation() {
        let session = LearningSession {
            session_id: "test_session".to_string(),
            start_time: 1234567890.0,
            end_time: None,
            states_processed: 0,
            learning_events: Vec::new(),
            session_metrics: SessionLearningMetrics::default(),
        };

        assert_eq!(session.session_id, "test_session");
        assert_eq!(session.states_processed, 0);
        assert!(session.learning_events.is_empty());
    }

    #[tokio::test]
    async fn test_learning_event_creation() {
        let metrics = LearningMetrics::default();
        let event = LearningEvent {
            timestamp: 1234567890.0,
            event_type: LearningEventType::StateUpdate,
            consciousness_id: "test_state".to_string(),
            metrics,
            metadata: HashMap::new(),
        };

        assert_eq!(event.consciousness_id, "test_state");
        assert!(matches!(event.event_type, LearningEventType::StateUpdate));
    }

    #[tokio::test]
    async fn test_learning_analytics_engine_creation() {
        let config = LearningAnalyticsConfig::default();
        let engine = LearningAnalyticsEngine::new(config);

        // Test basic functionality
        let current_session = engine.get_current_session().await;
        assert!(current_session.is_some()); // Should auto-start a session

        let patterns = engine.get_learning_patterns().await;
        assert!(patterns.is_empty()); // No patterns initially

        let metrics = engine.get_real_time_metrics().await;
        assert!(metrics.is_empty()); // No real-time metrics initially
    }
}
