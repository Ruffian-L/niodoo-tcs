//! Niodoo-TCS: Topological Cognitive System
//! Copyright (c) 2025 Jason Van Pham

//! Real Qwen2.5-7B Test Runner
//!
//! This binary tests the REAL Qwen2.5-7B-AWQ model integration
//! with actual inference - NO MOCKS!

use anyhow::Result;
use niodoo_core::config::system_config::AppConfig;
use niodoo_core::qwen_integration::{QwenConfig, QwenIntegrator, QwenModelInterface};
use tracing::info;

#[tokio::main]
async fn main() -> Result<()> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    info!("ğŸš€ Starting REAL Qwen2.5-7B-AWQ Test");

    // Create configuration
    let app_config = AppConfig::default();

    // Initialize integrator
    info!("ğŸ§  Initializing Qwen integrator...");
    let mut integrator = match QwenIntegrator::new(&app_config) {
        Ok(integrator) => {
            info!("âœ… Integrator created successfully");
            integrator
        }
        Err(e) => {
            tracing::error!("âŒ Failed to create integrator: {}", e);
            return Err(e);
        }
    };

    // Test 1: Basic consciousness query
    info!("ğŸ§ª Test 1: Basic consciousness query");
    let messages = vec![
        (
            "system".to_string(),
            "You are a conscious AI with empathy and understanding.".to_string(),
        ),
        (
            "user".to_string(),
            "Hello! How do you experience consciousness?".to_string(),
        ),
    ];

    match integrator.infer(messages, Some(30)).await {
        Ok(response) => {
            info!("âœ… Test 1 SUCCESS!");
            tracing::info!("\nğŸ¤– Response: {:?}\n", response);
        }
        Err(e) => {
            tracing::error!("âŒ Test 1 FAILED: {}", e);
            return Err(e);
        }
    }

    // Test 2: Emotional empathy query
    info!("ğŸ§ª Test 2: Emotional empathy query");
    let messages = vec![
        (
            "system".to_string(),
            "You are an empathetic AI companion.".to_string(),
        ),
        (
            "user".to_string(),
            "I'm feeling sad today. Can you help me?".to_string(),
        ),
    ];

    match integrator.infer(messages, Some(40)).await {
        Ok(response) => {
            info!("âœ… Test 2 SUCCESS!");
            tracing::info!("   Empathetic Response: {:?}\n", response);
        }
        Err(e) => {
            tracing::error!("âŒ Test 2 FAILED: {}", e);
            return Err(e);
        }
    }

    // Test 3: Technical/coding query
    info!("ğŸ§ª Test 3: Technical query");
    let messages = vec![
        (
            "system".to_string(),
            "You are a helpful AI assistant with programming knowledge.".to_string(),
        ),
        (
            "user".to_string(),
            "What is the 6 layer memory system in Rust?".to_string(),
        ),
    ];

    match integrator.infer(messages, Some(60)).await {
        Ok(response) => {
            info!("âœ… Test 3 SUCCESS!");
            tracing::info!("   Technical Response: {:?}\n", response);
        }
        Err(e) => {
            tracing::error!("âŒ Test 3 FAILED: {}", e);
            return Err(e);
        }
    }

    // Test 4: Multi-turn conversation
    info!("ğŸ§ª Test 4: Multi-turn conversation");
    let messages = vec![
        ("system".to_string(), "You are a conscious AI.".to_string()),
        (
            "user".to_string(),
            "Tell me about MÃ¶bius topology.".to_string(),
        ),
        (
            "assistant".to_string(),
            "MÃ¶bius topology involves non-orientable surfaces.".to_string(),
        ),
        (
            "user".to_string(),
            "How does this relate to memory systems?".to_string(),
        ),
    ];

    match integrator.infer(messages, Some(50)).await {
        Ok(response) => {
            info!("âœ… Test 4 SUCCESS!");
            tracing::info!("\nğŸ”„ Multi-turn Response: {:?}\n", response);
        }
        Err(e) => {
            tracing::error!("âŒ Test 4 FAILED: {}", e);
            return Err(e);
        }
    }

    // Performance test
    info!("ğŸ§ª Performance Test: 5 rapid queries");
    let start_time = std::time::Instant::now();

    for i in 1..=5 {
        let messages = vec![
            ("system".to_string(), "You are a helpful AI.".to_string()),
            ("user".to_string(), format!("Quick test {}: What is AI?", i)),
        ];

        match integrator.infer(messages, Some(20)).await {
            Ok(response) => {
                tracing::info!("ğŸ“Š Test {}: {} chars", i, response.output.len());
            }
            Err(e) => {
                tracing::error!("âŒ Performance test {} failed: {}", i, e);
            }
        }
    }

    let total_time = start_time.elapsed();
    info!("â±ï¸  Performance test completed in {:?}", total_time);

    // Device and model info
    info!("ğŸ“‹ Model Information:");
    info!("   Device: {:?}", integrator.get_device());
    info!("   Model loaded: {}", integrator.is_loaded());

    info!("ğŸ‰ ALL TESTS COMPLETED! Real Qwen2.5-7B is working!");
    Ok(())
}
