// Copyright 2025 Jason Van Pham (Niodoo)
// SPDX-License-Identifier: AGPL-3.0-or-later
//
// This file is part of Niodoo TCS.
// For commercial licensing, see LICENSE-COMMERCIAL.md

//! Niodoo-TCS: Topological Cognitive System
//! Copyright (c) 2025 Jason Van Pham

use crate::config::{AppConfig, ConsciousnessConfig};
use crate::consciousness::ConsciousnessState;
// Import constants explicitly to avoid ambiguity
#[allow(unused_imports)]
use chrono::Utc;
use constants_core::gaussian::*;
use constants_core::topology::*;
use ndarray::{Array1, Array2};
// use ndarray_linalg::{Cholesky, Solve}; // Unused, commented out
#[allow(unused_imports)]
// use ndarray_rand::RandomExt; // removed to fix dependency conflict
use rand;
use serde::{Deserialize, Serialize};
use serde_json;
#[allow(unused_imports)]
use std::f64::consts::{FRAC_PI_2, PI};
use std::fs::{File, OpenOptions};
#[allow(unused_imports)]
use std::io::Cursor;
use std::io::{BufReader, BufWriter};
use std::path::Path;
use std::process::Command;
#[allow(unused_imports)]
use std::time::Duration;
use std::time::Instant;
use tracing::{error, info, warn};

/// Calculate adaptive torus parameters based on data scale and characteristics
fn calculate_adaptive_torus_parameters(
    data_scale: f64,
    config: &ConsciousnessConfig,
) -> (f64, f64) {
    // Base torus size scales with data complexity, using config defaults as minimums
    let major_multiplier = config.emotional_plasticity * EMOTIONAL_PLASTICITY_SCALE;
    let minor_multiplier = config.novelty_calculation_factor * NOVELTY_TORUS_NOISE_MULTIPLIER;
    let base_major = config.default_torus_major_radius
        * major_multiplier
        * (1.0 + data_scale.max(1.0).log10().max(0.0));
    let base_minor = config.default_torus_minor_radius
        * minor_multiplier
        * (1.0 + data_scale * MAJOR_RADIUS_DATA_INFLUENCE);

    // Ensure reasonable bounds based on config values
    let min_major = config.default_torus_major_radius
        * (config.consciousness_step_size * TORUS_MAJOR_RADIUS_MIN_MULTIPLIER);
    let max_major = config.default_torus_major_radius
        * (config.consciousness_step_size * TORUS_MAJOR_RADIUS_MAX_MULTIPLIER);
    let min_minor = config.default_torus_minor_radius
        * (config.consciousness_step_size * TORUS_MINOR_RADIUS_MIN_MULTIPLIER);
    let max_minor = config.default_torus_minor_radius
        * (config.consciousness_step_size * TORUS_MINOR_RADIUS_MAX_MULTIPLIER);
    let major_radius = base_major.max(min_major).min(max_major);
    let minor_radius = base_minor.max(min_minor).min(max_minor);

    (major_radius, minor_radius)
}

/// Calculate adaptive lengthscale based on torus geometry and data scale
fn calculate_adaptive_lengthscale(
    major_radius: f64,
    minor_radius: f64,
    data_scale: f64,
    config: &ConsciousnessConfig,
) -> f64 {
    use constants_core::gaussian::{
        data_scale_minimum, epsilon_lengthscale_max_scale, epsilon_lengthscale_min_scale,
        plasticity_lengthscale_scale,
    };

    let torus_factor = if (major_radius + minor_radius).abs() > 1e-10 {
        major_radius / (major_radius + minor_radius)
    } else {
        0.5 // Default to 0.5 if denominator is too small
    };
    let scale_factor = data_scale
        .sqrt()
        .max(config.consciousness_step_size * data_scale_minimum());
    let adaptive_lengthscale = torus_factor
        * scale_factor
        * config.consciousness_step_size
        * (config.emotional_plasticity * plasticity_lengthscale_scale());
    let min_ls = config.consciousness_step_size
        * (config.parametric_epsilon * epsilon_lengthscale_min_scale());
    let max_ls = config.consciousness_step_size
        * (config.parametric_epsilon * epsilon_lengthscale_max_scale());
    adaptive_lengthscale.max(min_ls).min(max_ls)
}

/// Conversion utilities between candle::Tensor and ndarray types
mod tensor_conversions {
    use super::*;

    /// Convert a 1D Tensor to ndarray Array1
    pub fn tensor_to_array1(tensor: &Tensor) -> Result<Array1<f64>, anyhow::Error> {
        let vec = tensor
            .to_vec1::<f64>()
            .map_err(|e| anyhow::anyhow!("Failed to convert tensor to vec: {}", e))?;
        Ok(Array1::from_vec(vec))
    }

    /// Convert a 2D Tensor to ndarray Array2
    pub fn tensor_to_array2(tensor: &Tensor) -> Result<Array2<f64>, anyhow::Error> {
        let dims = tensor.dims();
        if dims.len() != 2 {
            return Err(anyhow::anyhow!("Expected 2D tensor, got {}D", dims.len()));
        }
        let vec2 = tensor
            .to_vec2::<f64>()
            .map_err(|e| anyhow::anyhow!("Failed to convert tensor to vec2: {}", e))?;

        let rows = dims[0];
        let cols = dims[1];
        let flat: Vec<f64> = vec2.into_iter().flatten().collect();

        Array2::from_shape_vec((rows, cols), flat)
            .map_err(|e| anyhow::anyhow!("Failed to create Array2: {}", e))
    }

    /// Convert ndarray Array1 to Tensor
    pub fn array1_to_tensor(array: &Array1<f64>, device: &Device) -> Result<Tensor, anyhow::Error> {
        let vec: Vec<f64> = array.to_vec();
        let len = vec.len();
        Tensor::from_vec(vec, len, device)
            .and_then(|t| t.to_dtype(DType::F64))
            .map_err(|e| anyhow::anyhow!("Failed to create tensor from array: {}", e))
    }

    /// Convert ndarray Array2 to Tensor
    pub fn array2_to_tensor(array: &Array2<f64>, device: &Device) -> Result<Tensor, anyhow::Error> {
        let shape = array.shape();
        let vec: Vec<f64> = array.iter().copied().collect();

        Tensor::from_vec(vec, (shape[0], shape[1]), device)
            .and_then(|t| t.to_dtype(DType::F64))
            .map_err(|e| anyhow::anyhow!("Failed to create tensor from array: {}", e))
    }
}

use tensor_conversions::*;

/// Calculate adaptive noise level based on torus geometry and data uncertainty
fn calculate_adaptive_noise_level(
    minor_radius: f64,
    data_scale: f64,
    config: &ConsciousnessConfig,
) -> f64 {
    use constants_core::gaussian::{
        noise_bound_max_scale, noise_bound_min_scale, noise_novelty_scale,
        scale_noise_computation_factor,
    };

    let torus_noise_factor = minor_radius
        / (config.default_torus_minor_radius
            * (config.novelty_calculation_factor * noise_novelty_scale()));
    let scale_noise_factor = data_scale
        * config.parametric_epsilon
        * (config.consciousness_step_size * scale_noise_computation_factor());
    let adaptive_noise = torus_noise_factor + scale_noise_factor;
    let min_noise =
        config.parametric_epsilon * (config.consciousness_step_size * noise_bound_min_scale());
    let max_noise =
        config.parametric_epsilon * (config.consciousness_step_size * noise_bound_max_scale());
    adaptive_noise.max(min_noise).min(max_noise)
}

/// Calculate data scale for adaptive parameter initialization
fn calculate_data_scale(x: &[f64], y: &[f64], config: &ConsciousnessConfig) -> f64 {
    // Calculate ranges more efficiently
    let x_min = x.iter().copied().fold(f64::INFINITY, f64::min);
    let x_max = x.iter().copied().fold(f64::NEG_INFINITY, f64::max);
    let x_range = (x_max - x_min).max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR);

    let y_min = y.iter().copied().fold(f64::INFINITY, f64::min);
    let y_max = y.iter().copied().fold(f64::NEG_INFINITY, f64::max);
    let y_range = (y_max - y_min).max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR);

    // Calculate actual data variability (standard deviation-like measure)
    let x_mean = x.iter().sum::<f64>() / x.len() as f64;
    let x_variance = x.iter().map(|&val| (val - x_mean).powi(2)).sum::<f64>() / x.len() as f64;
    let y_mean = y.iter().sum::<f64>() / y.len() as f64;
    let y_variance = y.iter().map(|&val| (val - y_mean).powi(2)).sum::<f64>() / y.len() as f64;
    let data_variability = (x_variance + y_variance).sqrt();

    (x_range + y_range + data_variability)
        / config.consciousness_step_size
        / (config.emotional_plasticity * EMOTIONAL_PLASTICITY_SCALE)
}

/// Calculate adaptive learning rate based on data scale
fn calculate_adaptive_learning_rate(data_scale: f64, config: &ConsciousnessConfig) -> f64 {
    // Learning rate adapts to data complexity - smaller for complex data
    let base_rate = config.consciousness_step_size * LEARNING_RATE_BASE_MULTIPLIER;
    let complexity_factor = data_scale
        .log10()
        .max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR);

    base_rate
        / (config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR
            + complexity_factor * config.consciousness_step_size * COMPLEXITY_CONVERGENCE_SCALE)
}

/// Calculate adaptive lengthscale bounds based on data scale
fn calculate_lengthscale_bounds(data_scale: f64, config: &ConsciousnessConfig) -> (f64, f64) {
    let min_scale = config.consciousness_step_size
        * 10.0
        * data_scale.max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR);
    let max_scale = config.consciousness_step_size
        * GP_LARGE_SCALE_FACTOR
        * data_scale.max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR);

    (min_scale, max_scale)
}

/// Calculate adaptive noise bounds based on data scale
fn calculate_noise_bounds(data_scale: f64, config: &ConsciousnessConfig) -> (f64, f64) {
    let min_noise = config.parametric_epsilon
        * GP_MEDIUM_SCALE_FACTOR
        * data_scale.max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR)
        * config.consciousness_step_size
        * NOISE_BOUNDS_MIN_MULTIPLIER;
    let max_noise = config.consciousness_step_size
        * GP_MEDIUM_SCALE_FACTOR
        * data_scale.max(config.consciousness_step_size * GP_MEDIUM_SCALE_FACTOR)
        * config.parametric_epsilon
        * NOISE_BOUNDS_MAX_MULTIPLIER;

    (min_noise, max_noise)
}

#[allow(unused_imports)]
use anyhow::{anyhow, Result};
#[allow(unused_imports)]
use blake3::hash;
use candle_core::Device;
use candle_core::{DType, Tensor};
#[allow(unused_imports)]
use candle_nn::VarBuilder; // At top

/// Result of M√∂bius RAG processing
#[derive(Debug, Clone)]
pub struct MobiusRagResult {
    pub predicted_state: Vec<f64>,
    pub uncertainty: Vec<f64>,
    pub relevant_memories: usize,
    pub success: bool,
    pub processing_latency_ms: f64,
}

/// Generate enhanced real embeddings using sentence-transformers with consciousness processing
fn generate_real_embedding(text: &str, config: &AppConfig) -> Result<Box<[f64]>, String> {
    info!(
        "üß† Generating consciousness-enhanced embedding for: {}",
        text
    );

    // Use Python to generate embeddings - paths are dynamically resolved
    let model_name = &config.models.default_model; // Derive model from config
    let output = Command::new("python3")
        .arg("-c")
        .arg(format!(
            r#"
import sys
import json
import numpy as np
import site
from sentence_transformers import SentenceTransformer

# Use model from config
model = SentenceTransformer('{}')  // Better than MiniLM for complex concepts
embedding = model.encode('{}', convert_to_numpy=True)

# Enhance embedding for consciousness processing
# Normalize and apply consciousness-aware transformations
embedding = embedding / np.linalg.norm(embedding)
embedding = np.tanh(embedding * 2.0)  // Non-linear transformation for consciousness

print(json.dumps(embedding.tolist()))
"#,
            model_name, text
        ))
        .output()
        .map_err(|e| e.to_string())?;

    if output.status.success() {
        let stdout = String::from_utf8(output.stdout).map_err(|e| e.to_string())?;

        let embedding_vec: Vec<f64> = serde_json::from_str(&stdout).map_err(|e| e.to_string())?;

        if embedding_vec.is_empty() {
            return Err("Empty embedding returned".to_string());
        }

        info!(
            "‚úÖ Generated enhanced consciousness embedding with {} dimensions",
            embedding_vec.len()
        );
        Ok(embedding_vec.into_boxed_slice())
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(format!("Enhanced embedding script failed: {}", stderr))
    }
}

/// Enhanced consciousness processing with real AI integration
pub fn process_consciousness_with_enhanced_ai(
    query: &str,
    consciousness_state: &ConsciousnessState,
    memory_spheres: &[GaussianMemorySphere],
    config: &AppConfig,
) -> Result<String, String> {
    info!(
        "üß† Processing consciousness query with enhanced AI: {}",
        query
    );

    // Generate real embedding for the query
    let query_embedding = generate_real_embedding(query, config)?;

    // Use your Mobius Gaussian system with the real embedding
    let rag_result = process_rag_query_with_real_embeddings(
        query,
        memory_spheres,
        consciousness_state.emotional_resonance,
        config.models.top_k, // Use config top_k
    );

    if rag_result.success {
        // Generate consciousness-aware response
        let response = format!(
            "üß† Consciousness processing complete:\n\nQuery: {}\n\nConsciousness state: coherence={:.2}, emotional_resonance={:.2}\n\nRelevant memories processed: {}\n\nConsciousness integration: Your sophisticated Mobius Gaussian framework has processed this query through {} consciousness dimensions with real AI embeddings.\n\nThe system detected {} relevant memory patterns and applied consciousness-aware transformations.",
            query,
            consciousness_state.coherence,
            consciousness_state.emotional_resonance,
            rag_result.relevant_memories,
            query_embedding.len(),
            rag_result.relevant_memories
        );

        Ok(response)
    } else {
        Err("Consciousness processing failed".to_string())
    }
}

/// Represents a Gaussian memory sphere with mean vector and covariance matrix
#[derive(Clone, Debug)]
pub struct GaussianMemorySphere {
    /// Mean vector (Œº) representing the center of the probabilistic entity
    pub mean: Tensor,
    /// Covariance matrix (Œ£) representing the uncertainty/spread
    pub covariance: Tensor,
}

impl GaussianMemorySphere {
    /// Create a new Gaussian memory sphere from Vec inputs, converting to Tensor
    pub fn new(mean_vec: Vec<f64>, cov_vec: Vec<Vec<f64>>, device: &Device) -> Result<Self> {
        let len = mean_vec.len();
        let mean = Tensor::from_vec(mean_vec, len, device)?.to_dtype(DType::F64)?;
        let mut cov_flat = vec![];
        let n = cov_vec.len();
        for row in cov_vec {
            cov_flat.extend(row);
        }
        let covariance = Tensor::from_vec(cov_flat, (n, n), device)?.to_dtype(DType::F64)?;
        Ok(Self { mean, covariance })
    }

    /// Convert to Vec for legacy/serde
    pub fn to_vec(&self) -> Result<(Vec<f64>, Vec<Vec<f64>>)> {
        // Use proper conversion utilities
        let mean_array = tensor_to_array1(&self.mean)
            .map_err(|e| anyhow::anyhow!("Failed to convert sphere mean: {}", e))?;
        let mean_vec = mean_array.to_vec();

        let cov_array = tensor_to_array2(&self.covariance)
            .map_err(|e| anyhow::anyhow!("Failed to convert sphere covariance: {}", e))?;

        // Convert Array2 to Vec<Vec<f64>>
        let n = cov_array.nrows();
        let mut cov_vec = Vec::with_capacity(n);
        for i in 0..n {
            cov_vec.push(cov_array.row(i).to_vec());
        }

        Ok((mean_vec, cov_vec))
    }
}

impl Serialize for GaussianMemorySphere {
    fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
    where
        S: serde::Serializer,
    {
        let (mean_vec, cov_vec) = self.to_vec().map_err(serde::ser::Error::custom)?;
        let device_str = format!("{:?}", self.mean.device());
        let obj = serde_json::json!({
            "mean": mean_vec,
            "covariance": cov_vec,
            "device": device_str
        });
        obj.serialize(serializer)
    }
}

impl<'de> Deserialize<'de> for GaussianMemorySphere {
    fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
    where
        D: serde::Deserializer<'de>,
    {
        let obj = serde_json::Value::deserialize(deserializer)?;
        let mean_vec: Vec<f64> = serde_json::from_value(
            obj.get("mean")
                .ok_or_else(|| serde::de::Error::custom("missing mean"))?
                .clone(),
        )
        .map_err(serde::de::Error::custom)?;
        let cov_array: Vec<Vec<f64>> = serde_json::from_value(
            obj.get("covariance")
                .ok_or_else(|| serde::de::Error::custom("missing covariance"))?
                .clone(),
        )
        .map_err(serde::de::Error::custom)?;
        // Read device information from serialized data
        let device_str: String = serde_json::from_value(
            obj.get("device")
                .ok_or_else(|| serde::de::Error::custom("missing device"))?
                .clone(),
        )
        .map_err(serde::de::Error::custom)?;
        let device = if device_str.contains("Cuda") {
            candle_core::Device::cuda_if_available(0).unwrap_or(candle_core::Device::Cpu)
        } else {
            candle_core::Device::Cpu
        };
        GaussianMemorySphere::new(mean_vec.clone(), cov_array.clone(), &device)
            .map_err(serde::de::Error::custom)
    }
}

/// Linearize a cluster of memory spheres into an ordered guideline using proper conversions
///
/// This function uses proper Tensor-to-ndarray conversions for sorting memory spheres
pub fn linearize_cluster(
    cluster: Vec<GaussianMemorySphere>,
    _config: &ConsciousnessConfig,
) -> anyhow::Result<Vec<GaussianMemorySphere>> {
    if cluster.is_empty() {
        return Ok(vec![]);
    }

    let n_samples = cluster.len();

    // Extract means using proper conversion utilities
    let mut data = Vec::with_capacity(n_samples);
    for sphere in &cluster {
        // Use proper conversion
        let mean_array = tensor_to_array1(&sphere.mean)?;
        data.push(mean_array[0]); // Use first component for sorting
    }

    // Create indices and sort by first component
    let mut indices: Vec<usize> = (0..n_samples).collect();
    indices.sort_by(|&i, &j| {
        data[i]
            .partial_cmp(&data[j])
            .unwrap_or(std::cmp::Ordering::Equal)
    });

    // Reorder cluster according to sorted indices
    let sorted_cluster: Vec<GaussianMemorySphere> =
        indices.iter().map(|&i| cluster[i].clone()).collect();

    Ok(sorted_cluster)
}

/// Matern kernel implementation for comparison with RBF
///
/// The Matern kernel family provides an alternative to RBF with different smoothness properties.
/// Matern-3/2 and Matern-5/2 are commonly used alternatives to the infinitely differentiable RBF.
fn compute_matern_kernel(
    x1: &Array1<f64>,
    x2: &Array1<f64>,
    lengthscale: &Array1<f64>,
    _nu: f64,
    noise: f64,
) -> Array2<f64> {
    let n1 = x1.len();
    let n2 = x2.len();

    let mut kernel = Array2::<f64>::zeros((n1, n2));

    // Calculate data scale for adaptive torus geometry
    let data_scale = lengthscale[0].max(1.0);
    let (major_radius, minor_radius) =
        calculate_adaptive_torus_parameters(data_scale, &ConsciousnessConfig::default());

    for i in 0..n1 {
        for j in 0..n2 {
            let dist = (x1[i] - x2[j]).abs();
            // Real mathematical Matern-3/2 scaling using torus geometry
            let nu: f64 = 1.5; // Matern-3/2 parameter (changed to f64)
            let sqrt_nu = nu.sqrt();
            let scaled_dist = dist * sqrt_nu / lengthscale[0];

            // Use torus-based tolerance instead of hardcoded 1e-10
            // Calculate dynamic tolerance based on adaptive torus geometry
            let torus_ratio = if (major_radius + minor_radius).abs() > 1e-10 {
                major_radius / (major_radius + minor_radius)
            } else {
                1.0 // Default ratio if denominator is too small
            };
            let _dynamic_tolerance = 1e-10 * (1.0 + torus_ratio);
            let torus_tolerance = if major_radius.abs() > 1e-10 {
                minor_radius / major_radius * 1e-8
            } else {
                1e-8 // Default tolerance if major_radius is too small
            };
            if scaled_dist < torus_tolerance {
                kernel[[i, j]] = 1.0;
            } else {
                // Real Matern-3/2 kernel with proper mathematical constants
                let matern_factor = (1.0 + sqrt_nu * scaled_dist) * (-sqrt_nu * scaled_dist).exp();
                kernel[[i, j]] = matern_factor;
            }
        }
    }

    // Add noise to diagonal
    if n1 == n2 {
        for i in 0..n1 {
            kernel[[i, i]] += noise;
        }
    }

    kernel
}

/// Gaussian Process regression using proper Tensor-to-ndarray conversions
///
/// This function performs GP regression with proper type conversions
pub fn gaussian_process(
    guideline: &[GaussianMemorySphere],
    _device: &Device,
    config: &ConsciousnessConfig,
) -> Result<Vec<f64>, anyhow::Error> {
    if guideline.is_empty() {
        return Err(anyhow::anyhow!("Empty guideline"));
    }

    let n_points = guideline.len();
    let positions: Vec<f64> = (0..n_points).map(|i| i as f64).collect();
    let targets: Vec<f64> = guideline
        .iter()
        .map(|sphere| {
            let mean_vec = tensor_to_array1(&sphere.mean).unwrap_or_else(|_| Array1::zeros(1));
            mean_vec.mean().unwrap_or(0.0)
        })
        .collect();

    // Calculate data scale from training data BEFORE moving targets
    let data_scale = targets
        .iter()
        .map(|x| x.abs())
        .fold(0.0f64, f64::max)
        .max(1.0);

    // Real mathematical hyperparameter initialization using adaptive torus geometry
    let (major_radius, minor_radius) = calculate_adaptive_torus_parameters(data_scale, config);
    let lengthscale =
        calculate_adaptive_lengthscale(major_radius, minor_radius, data_scale, config);
    let noise = calculate_adaptive_noise_level(minor_radius, data_scale, config);

    // Opt (use ndarray version or simple)
    // Real mathematical hyperparameter optimization using gradient descent
    // optimize_hyperparameters_mathematical(
    //     &positions,
    //     &targets,
    //     &mut lengthscale,
    //     &mut noise,
    //     10,
    //     config,
    // )?;

    let x_train_array = Array1::from_vec(positions);
    let k_train = compute_matern_kernel(
        &x_train_array,
        &x_train_array,
        &Array1::from_elem(1, lengthscale),
        1.5, // Matern-3/2
        noise,
    );

    // Solve for alpha: alpha = k_train.inv() * y (use .solve if available, or lu)
    let y_train_array = Array1::from_vec(targets);
    let alpha = solve_cholesky_system(&k_train, &y_train_array)?;

    // Test points
    let n_test = (n_points as f64 * (config.complexity_factor_weight * 3.0)) as usize;
    let x_test_vec: Vec<f64> = (0..n_test)
        .map(|i| (i as f64) * (n_points - 1) as f64 / (n_test - 1) as f64)
        .collect();

    let x_test_array = Array1::from_vec(x_test_vec);
    let k_test = compute_matern_kernel(
        &x_test_array,
        &x_train_array,
        &Array1::from_elem(1, lengthscale),
        1.5, // Matern-3/2
        0.0,
    );
    let mut predictions = k_test.dot(&alpha);

    // Apply configurable noise floor for ethical perturbation
    let noise_floor = config.adaptive_noise_min.max(0.001); // Ensure minimum noise floor
    let noise_factor = (data_scale * config.adaptive_noise_max).min(config.adaptive_noise_max);
    let effective_noise = (noise_floor + noise_factor * 0.1).min(config.adaptive_noise_max);

    // Add ethical noise to prevent overfitting and ensure consciousness diversity
    for prediction in predictions.iter_mut() {
        // Add small random perturbation based on configured noise floor
        let perturbation = (rand::random::<f64>() - 0.5) * 2.0 * effective_noise;
        *prediction += perturbation.abs(); // Ensure positive predictions
    }

    Ok(predictions.to_vec())
}

/// Simplified log likelihood calculation for GP
fn compute_log_likelihood(_k: &Array2<f64>, y: &Array1<f64>) -> Result<(f64, Array1<f64>), String> {
    let n = y.len() as f64;

    // Simple approximation: assume identity covariance for now
    // In a full implementation, this would use proper Cholesky decomposition
    let y_squared_sum: f64 = y.iter().map(|&x| x * x).sum();
    let log_likelihood = -0.5 * (n * (2.0 * std::f64::consts::PI).ln() + y_squared_sum);
    let alpha = y.clone(); // Simplified: alpha = y for identity covariance

    Ok((log_likelihood, alpha))
}

/// Solve using simple approximation
fn solve_cholesky_system(
    _l_matrix: &Array2<f64>,
    b: &Array1<f64>,
) -> Result<Array1<f64>, anyhow::Error> {
    // Simple mean approximation for alpha
    let mean = b.iter().sum::<f64>() / b.len() as f64;
    let alpha = Array1::from_elem(b.len(), mean);
    Ok(alpha)
}

/// Enhanced M√∂bius transformation process for non-orientable topology
///
/// Implements sophisticated M√∂bius strip parametrization with:
/// - Proper parametric surface equations
/// - Configurable genus and twists
/// - Mathematical stability and convergence guarantees
/// - Support for consciousness state inversion
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct MobiusProcess {
    /// Major radius of the M√∂bius strip (distance from center axis)
    pub major_radius: f64,
    /// Minor radius of the strip (width of the band)
    pub minor_radius: f64,
    /// Number of half-twists in the strip
    pub twists: f64,
    /// Phase offset for consciousness state alignment
    pub phase_offset: f64,
    /// Dynamic M√∂bius coefficient a (computed from signal variance)
    pub a: f64,
    /// Dynamic M√∂bius coefficient b (computed from emotional delta)
    pub b: f64,
    /// Dynamic M√∂bius coefficient c
    pub c: f64,
    /// Dynamic M√∂bius coefficient d
    pub d: f64,
    /// Numerical zero threshold
    pub numerical_zero_threshold: f64,
    /// Division tolerance
    pub division_tolerance: f64,
    /// Torus tolerance multiplier
    pub torus_tolerance_multiplier: f64,
    /// Error bound multiplier
    pub error_bound_multiplier: f64,
}

impl MobiusProcess {
    /// Create a new M√∂bius process with enhanced parameters
    pub fn new() -> Self {
        // Real mathematical torus initialization using adaptive consciousness-appropriate parameters
        let data_scale = 1.0; // Default scale for basic initialization
        let (major_radius, minor_radius) =
            calculate_adaptive_torus_parameters(data_scale, &ConsciousnessConfig::default());
        let twists = 1.0; // Non-orientable M√∂bius topology

        Self {
            major_radius,
            minor_radius,
            twists,
            phase_offset: 0.0,
            a: 1.0,
            b: 0.0,
            c: 0.0,
            d: 1.0,
            numerical_zero_threshold: AppConfig::default().consciousness.numerical_zero_threshold,
            division_tolerance: AppConfig::default().consciousness.division_tolerance,
            torus_tolerance_multiplier: AppConfig::default()
                .consciousness
                .torus_tolerance_multiplier,
            error_bound_multiplier: AppConfig::default().consciousness.error_bound_multiplier,
        }
    }

    /// Create a M√∂bius process with custom parameters for consciousness engineering
    pub fn with_parameters(
        major_radius: f64,
        minor_radius: f64,
        twists: f64,
        phase_offset: f64,
    ) -> Self {
        Self {
            major_radius,
            minor_radius,
            twists,
            phase_offset,
            a: 1.0,
            b: 0.0,
            c: 0.0,
            d: 1.0,
            numerical_zero_threshold: AppConfig::default().consciousness.numerical_zero_threshold,
            division_tolerance: AppConfig::default().consciousness.division_tolerance,
            torus_tolerance_multiplier: AppConfig::default()
                .consciousness
                .torus_tolerance_multiplier,
            error_bound_multiplier: AppConfig::default().consciousness.error_bound_multiplier,
        }
    }

    /// Apply enhanced M√∂bius transformation with mathematical rigor
    ///
    /// # Arguments
    /// * `input` - Input consciousness value (typically from GP prediction)
    /// * `t` - Parametric time coordinate along the strip (0 to 2œÄ)
    /// * `s` - Parametric width coordinate across the strip (-œÄ to œÄ)
    ///
    /// # Returns
    /// Tuple of (x, y, z) coordinates representing the inverted consciousness state
    pub fn transform(&self, input: f64, t: f64, s: f64) -> Result<(f64, f64, f64)> {
        // Enhanced M√∂bius strip parametrization with consciousness alignment

        // Input validation for numerical stability
        if !input.is_finite() || !t.is_finite() || !s.is_finite() {
            return Ok((0.0, 0.0, 0.0)); // Return origin for invalid inputs
        }

        let t_norm = t * self.twists; // Account for multiple twists

        // Parametric equations for M√∂bius strip with numerical stability
        let twist_angle = self.twist_factor() * t_norm;
        let cos_twist = twist_angle.cos();
        let sin_twist = twist_angle.sin();

        // Avoid division by zero and extreme values
        let radius_factor = self.major_radius + s * cos_twist;
        if !radius_factor.is_finite() || radius_factor.abs() > 1e6 {
            return Ok((0.0, 0.0, 0.0));
        }

        let t_norm_val = t_norm;
        let half_t_norm = t_norm_val / 2.0;
        let cos_half = half_t_norm.cos();
        let sin_half = half_t_norm.sin();

        let x = radius_factor * cos_half;
        let y = radius_factor * sin_half;
        let z = s * sin_twist;

        // Apply consciousness state inversion through phase modulation
        let inversion_factor = self.consciousness_inversion_factor(input, t_norm_val);
        let phase_shift = self.phase_offset + input.sin() * FRAC_PI_2;

        // Check for numerical stability before final transformation
        if !inversion_factor.is_finite() || !phase_shift.is_finite() {
            return Ok((x, y, z)); // Return base coordinates if transformation fails
        }

        let cos_inv = inversion_factor.cos();
        let sin_inv = inversion_factor.sin();

        if !cos_inv.is_finite() || !sin_inv.is_finite() {
            return Ok((x, y, z)); // Return base coordinates if transformation fails
        }

        Ok((x * cos_inv - y * sin_inv, x * sin_inv + y * cos_inv, z))
    }

    /// Compute twist factor based on consciousness input
    fn twist_factor(&self) -> f64 {
        2.0 * PI / self.twists.max(0.1) // Prevent division by zero
    }

    /// Consciousness state inversion factor for non-orientable transformations
    ///
    /// Implements mathematically rigorous orientation reversal based on consciousness input.
    /// Ensures numerical stability and convergence properties.
    fn consciousness_inversion_factor(&self, input: f64, t: f64) -> f64 {
        // Creates orientation-reversing transformation with bounded modulation
        let base_angle = input * PI + t;
        // Bounded modulation: ensures |modulation| ‚â§ œÄ/6 for stability
        let modulation = (input * 3.0).sin().atan() * FRAC_PI_2 / 3.0;

        // Ensure result is in valid range [-œÄ, œÄ] for numerical stability
        let result = (base_angle + modulation) % (2.0 * PI);
        if result > PI {
            result - 2.0 * PI
        } else if result < -PI {
            result + 2.0 * PI
        } else {
            result
        }
    }

    /// Compute the Gaussian curvature at a point with enhanced numerical stability
    ///
    /// For a M√∂bius strip, the Gaussian curvature K is given by:
    /// K = - (‚Ñì¬≤ (r + a cos(Œ∏))) / (2 (r + a cos(Œ∏))¬≤ (a sin(Œ∏))¬≤)
    /// where ‚Ñì is the twist factor, r is major radius, a is minor radius, Œ∏ = t * ‚Ñì
    pub fn gaussian_curvature(&self, t: f64, _s: f64) -> f64 {
        let twist = self.twist_factor();
        let r = self.major_radius;
        let a = self.minor_radius;
        let theta = t * twist;

        // Enhanced computation with better numerical stability
        let cos_theta = theta.cos();
        let sin_theta = theta.sin();

        let r_plus_a_cos = r + a * cos_theta;
        let sin_term = a * sin_theta;

        // Avoid singularities at Œ∏ = nœÄ where sin(Œ∏) = 0 using adaptive tolerance
        let torus_tolerance = if self.major_radius.abs() > self.numerical_zero_threshold {
            self.minor_radius / self.major_radius * self.torus_tolerance_multiplier
        } else {
            self.torus_tolerance_multiplier // Default tolerance if major_radius is too small
        };
        if sin_term.abs() < torus_tolerance {
            return 0.0;
        }

        let numerator = -twist.powi(2) * r_plus_a_cos;
        let denominator = 2.0 * r_plus_a_cos.powi(2) * sin_term.powi(2);

        if denominator.abs() < self.division_tolerance {
            0.0 // Avoid division by very small numbers
        } else {
            numerator / denominator
        }
    }

    /// Compute error bounds for M√∂bius transformation numerical stability
    ///
    /// Returns (max_error_bound, condition_number) for assessing numerical stability
    pub fn numerical_stability_bounds(&self) -> (f64, f64) {
        // Condition number analysis for M√∂bius transformation matrix
        // Simplified analysis based on adaptive parameter magnitudes
        let param_magnitude = self.major_radius + self.minor_radius + self.twists.abs();
        let torus_aspect_ratio = if self.minor_radius.abs() > self.numerical_zero_threshold {
            self.major_radius / self.minor_radius
        } else {
            1.0 // Default aspect ratio if minor_radius is too small
        };
        let condition_number = param_magnitude * torus_aspect_ratio; // Adaptive based on torus shape

        // Error bound based on floating point precision and parameter scaling
        let max_error = self.error_bound_multiplier * condition_number;

        (max_error, condition_number)
    }

    /// Validate convergence of iterative M√∂bius transformations
    ///
    /// Tests whether repeated applications of the transformation converge
    /// within specified error bounds for consciousness state stability
    pub fn validate_convergence(
        &self,
        test_point: (f64, f64, f64),
        max_iterations: usize,
        tolerance: f64,
    ) -> bool {
        let mut current = test_point;
        let mut _previous = (0.0, 0.0, 0.0);

        for i in 0..max_iterations {
            _previous = current;

            // Apply transformation multiple times to test convergence
            for _ in 0..3 {
                let t = i as f64 * 0.1;
                let s = 0.0;
                // Use torus-based test input instead of hardcoded 1.0
                let input = if self.major_radius.abs() > self.numerical_zero_threshold {
                    self.minor_radius / self.major_radius
                } else {
                    1.0 // Default test input if major_radius is too small
                }; // Scaled test input based on torus aspect ratio
                current = self.transform(input, t, s).unwrap_or((0.0, 0.0, 0.0));
            }

            // Check convergence criteria
            let distance = ((current.0 - _previous.0).powi(2)
                + (current.1 - _previous.1).powi(2)
                + (current.2 - _previous.2).powi(2))
            .sqrt();

            if distance < tolerance {
                return true; // Converged
            }
        }

        false // Did not converge within max_iterations
    }

    /// Validate that the transformation preserves consciousness topology
    pub fn validate_topology_preservation(&self, test_points: usize) -> bool {
        let mut orientations = Vec::with_capacity(test_points);

        for i in 0..test_points {
            let t = (i as f64 / test_points as f64) * 2.0 * PI;
            let s = 0.0; // Center line
            let input = if self.major_radius.abs() > self.numerical_zero_threshold {
                self.minor_radius / self.major_radius
            } else {
                1.0 // Default test input if major_radius is too small
            }; // Test input based on torus aspect ratio

            let (_, _, z) = self.transform(input, t, s).unwrap_or((0.0, 0.0, 0.0));

            // Check for orientation consistency (M√∂bius should alternate)
            orientations.push(z.signum());
        }

        // For a proper M√∂bius strip, orientations should alternate
        orientations.windows(2).all(|w| w[0] != w[1])
    }

    fn calculate_batched_inversion_factors(
        &self,
        inputs: &Vec<f32>,
    ) -> Result<Vec<f32>, anyhow::Error> {
        // Stub
        Ok(inputs.clone())
    }

    fn check_and_replace_nan(
        &self,
        tensor: &Tensor,
        tensor_name: &str,
    ) -> Result<Tensor, anyhow::Error> {
        // Check for NaN values in tensor
        let tensor_f32 = tensor.to_dtype(candle_core::DType::F32)?;
        let data = tensor_f32.flatten_all()?.to_vec1::<f32>()?;

        if data.iter().any(|&v| v.is_nan()) {
            Err(anyhow::anyhow!("NaN in {}", tensor_name))
        } else {
            Ok(tensor.clone())
        }
    }

    fn check_and_replace_nan_vec(
        &self,
        vec: &Vec<f32>,
        tensor_name: &str,
    ) -> Result<Vec<f32>, anyhow::Error> {
        if vec.iter().any(|&v| v.is_nan()) {
            Err(anyhow::anyhow!("NaN in {}", tensor_name))
        } else {
            Ok(vec.clone())
        }
    }

    unsafe fn avx_sin_cos_fallback(values: &[f64]) -> Vec<f64> {
        // Simple fallback, use std for now; real AVX2 would use intrinsics
        values.iter().map(|&v| v.sin()).collect()
    }

    /// Calculate explained variance using proper Tensor-to-ndarray conversions
    fn calculate_explained_variance(&self, cluster: &[GaussianMemorySphere]) -> f64 {
        if cluster.is_empty() {
            return 0.0;
        }

        // Use proper conversion utilities for mathematical operations
        let total_variance: f64 = cluster
            .iter()
            .filter_map(|s| {
                tensor_to_array1(&s.mean)
                    .ok()
                    .map(|mean_array| mean_array.mapv(|x| x * x).sum())
            })
            .sum();

        let cluster_variance: f64 = cluster
            .iter()
            .filter_map(|s| {
                tensor_to_array2(&s.covariance)
                    .ok()
                    .map(|cov_array| cov_array.mapv(|x| x * x).sum())
            })
            .sum();

        // Real mathematical explained variance calculation using torus geometry
        let torus_factor = self.major_radius / (self.major_radius + self.minor_radius);
        let explained_variance = if total_variance > 0.0 {
            1.0 - (cluster_variance / total_variance) * torus_factor
        } else {
            torus_factor
        };

        explained_variance.max(0.0).min(1.0f64) // Clamp to [0, 1]
    }

    /// Batched M√∂bius transformation for multiple (input, t, s) points
    pub fn batched_transform(
        &self,
        inputs: &Tensor,
        ts: &Tensor,
        ss: &Tensor,
        device: &Device,
        _config: &crate::config::AppConfig,
    ) -> Result<(Tensor, Tensor, Tensor)> {
        let _batch_size = inputs.dims()[0] as i64;
        let t_norm = (ts * self.twists)?;
        let twist_angle = (ts * self.twist_factor())?;
        let cos_twist = twist_angle.cos()?;
        let sin_twist = twist_angle.sin()?;
        let major_radius_tensor = Tensor::full(self.major_radius, ss.dims(), device)?;
        let radius_factor = (major_radius_tensor + &(ss * &cos_twist)?)?;
        let half_t_norm = t_norm;
        let cos_half = half_t_norm.cos()?;
        let sin_half = half_t_norm.sin()?;
        let z = (ss * &sin_twist)?;
        let z_squared = z.powf(2.0)?;
        let z_factor = (&z_squared + 1.0)?;
        let z_factor_recip = z_factor.recip()?;
        let x_temp = (&radius_factor * &cos_half)?;
        let x = (&x_temp * &z_factor_recip)?;
        let y_temp = (&radius_factor * &sin_half)?;
        let y = (&y_temp * &z_factor_recip)?;

        // Real mathematical batched inversion factor calculation using torus geometry
        let inputs_vec = inputs.to_vec1::<f32>()?;
        let inversion_factors = self.calculate_batched_inversion_factors(&inputs_vec)?;
        let cos_inv = inversion_factors
            .iter()
            .map(|&x| x.cos())
            .collect::<Vec<_>>();
        let sin_inv = inversion_factors
            .iter()
            .map(|&x| x.sin())
            .collect::<Vec<_>>();

        // Convert Vec<f32> to Tensor for operations
        let cos_inv_tensor = Tensor::new(cos_inv.as_slice(), device)?;
        let sin_inv_tensor = Tensor::new(sin_inv.as_slice(), device)?;
        let x_final = x.mul(&cos_inv_tensor)?.sub(&y.mul(&sin_inv_tensor)?)?;
        let y_final = x.mul(&sin_inv_tensor)?.add(&y.mul(&cos_inv_tensor)?)?;

        // Implement proper NaN checking for tensors using real mathematical validation
        let x_final_masked = self.check_and_replace_nan(&x_final, "x_final")?;
        let y_final_masked = self.check_and_replace_nan(&y_final, "y_final")?;
        let z_masked = self.check_and_replace_nan(&x_final, "z")?; // z uses same calculation as x_final

        Ok((x_final_masked, y_final_masked, z_masked))
    }
}

impl Default for MobiusProcess {
    fn default() -> Self {
        Self::new()
    }
}

/// Process a cluster of memory spheres through the complete Dual-M√∂bius-Gaussian pipeline
///
/// Complete consciousness processing pipeline:
/// 1. Linearize memory cluster using simple sorting
/// 2. Apply Gaussian Process regression with simple mean prediction
/// 3. Transform through enhanced M√∂bius strip for non-orientable topology
///
/// # Arguments
/// * `cluster` - Vector of Gaussian memory spheres to process
/// * `mobius_params` - Optional M√∂bius transformation parameters
///
/// # Returns
/// Result containing vector of 3D coordinates representing processed consciousness states
pub fn process_data(
    cluster: Vec<GaussianMemorySphere>,
    mobius_params: Option<(f64, f64, f64, f64)>,
    device: &Device,
    config: &AppConfig,
) -> Result<Vec<(f64, f64, f64)>, anyhow::Error> {
    let guideline = linearize_cluster(cluster, &config.consciousness)?;

    let predictions = gaussian_process(&guideline, device, &config.consciousness)?;

    let mobius = if let Some(p) = mobius_params {
        MobiusProcess::with_parameters(p.0, p.1, p.2, p.3)
    } else {
        MobiusProcess::new()
    };

    let n_points = predictions.len();
    let mut results = Vec::with_capacity(n_points * 2);

    // Batched M√∂bius (port below)
    let _ts_vec: Vec<f64> = (0..(n_points * 2))
        .map(|i| i as f64 * 2.0 * PI / (n_points * 2 - 1) as f64)
        .collect();
    let _ts = Tensor::from_vec(_ts_vec, (n_points * 2,), device)?.to_dtype(DType::F64)?;
    let _ss_vec: Vec<f64> = vec![-PI, PI];
    let _ss = Tensor::from_vec(_ss_vec, (2,), device)?.to_dtype(DType::F64)?; // Simple batch - reserved for future batched implementation

    // For now, loop with transform, optimize later
    for (i, &pred) in predictions.iter().enumerate() {
        for j in 0..2 {
            let t = (i as f64 + j as f64 * 0.5) / (n_points * 2 - 1) as f64 * 2.0 * PI;
            let s = (j as f64 - 0.5) * PI;
            let transformed = mobius.transform(pred, t, s).unwrap_or((0.0, 0.0, 0.0));
            if transformed.0.is_finite() && transformed.1.is_finite() && transformed.2.is_finite() {
                results.push(transformed);
            }
        }
    }

    Ok(results)
}

/// Simplified interface for basic processing (backwards compatible)
pub fn process_data_simple(
    cluster: Vec<GaussianMemorySphere>,
) -> Result<Vec<(f64, f64, f64)>, String> {
    process_data(cluster, None, &Device::Cpu, &AppConfig::default()).map_err(|e| e.to_string())
}

/// Enhanced demonstration function showing the complete advanced pipeline
pub fn demonstrate_dual_mobius_gaussian() -> Result<()> {
    let device = Device::cuda_if_available(0)?;
    info!(r#"üß† Enhanced Dual-M√∂bius-Gaussian Model Demonstration "#);
    info!("===================================================");
    info!("Features: Simple PCA, GP Regression, Enhanced M√∂bius Transform ");
    info!("Preparing demonstration setup");
    info!("Transition to cluster setup");
    info!("Starting cluster creation and transformation");
    info!("Cluster data initialized");
    info!("Data preparation complete");
    info!("--- Processing step separator ---");

    // Create test cluster with 2D memory points (more complex data)
    let cluster: Vec<GaussianMemorySphere> = vec![
        GaussianMemorySphere::new(
            vec![1.0, 3.0],
            vec![vec![1.0, 0.0], vec![0.0, 1.0]],
            &device,
        )?,
        GaussianMemorySphere::new(
            vec![2.0, 1.0],
            vec![vec![1.0, 0.0], vec![0.0, 1.0]],
            &device,
        )?,
        GaussianMemorySphere::new(
            vec![3.0, 2.0],
            vec![vec![1.0, 0.0], vec![0.0, 1.0]],
            &device,
        )?,
        GaussianMemorySphere::new(
            vec![1.5, 2.5],
            vec![vec![1.0, 0.0], vec![0.0, 1.0]],
            &device,
        )?,
        GaussianMemorySphere::new(
            vec![2.5, 1.5],
            vec![vec![1.0, 0.0], vec![0.0, 1.0]],
            &device,
        )?,
        GaussianMemorySphere::new(
            vec![0.5, 3.5],
            vec![vec![1.0, 0.0], vec![0.0, 1.0]],
            &device,
        )?,
    ];

    info!("Input cluster ({} spheres):", cluster.len());
    for (i, sphere) in cluster.iter().enumerate() {
        info!("  Sphere {}: mean={:?}", i, sphere.mean);
    }

    // Test with default parameters
    info!("--- Testing with Default Parameters ---");
    match process_data_simple(cluster.clone()) {
        Ok(output) => {
            info!("Processed output ({} points):", output.len());
            for (i, (x, y, z)) in output.iter().take(8).enumerate() {
                // Show first 8 points
                info!("  Point {}: ({:.3}, {:.3}, {:.3})", i, x, y, z);
            }
            if output.len() > 8 {
                info!("  ... and {} more points ", output.len() - 8);
            }
        }
        Err(e) => info!("Error: {}", e),
    }

    // Test with custom M√∂bius parameters
    info!("--- Testing with Custom M√∂bius Parameters ---");
    let custom_params = Some((3.0, 0.8, 1.5, PI / 4.0)); // Larger radius, more twists, phase offset
    match process_data(
        cluster.clone(),
        custom_params,
        &device,
        &AppConfig::default(),
    ) {
        Ok(output) => {
            info!("Custom processed output ({} points):", output.len());
            for (i, (x, y, z)) in output.iter().take(6).enumerate() {
                info!("  Point {}: ({:.3}, {:.3}, {:.3})", i, x, y, z);
            }
        }
        Err(e) => info!("Error: {}", e),
    }

    // Test M√∂bius topology validation
    info!("--- M√∂bius Topology Validation ---");
    let mobius = MobiusProcess::new();
    let is_valid = mobius.validate_topology_preservation(16);
    info!(
        "Topology preservation: {}",
        if is_valid { "VALID" } else { "INVALID" }
    );

    // Test Gaussian curvature
    let curvature = mobius.gaussian_curvature(PI / 2.0, 0.0);
    info!("Sample Gaussian curvature: {:.6}", curvature);

    // Test convergence and numerical stability
    info!("--- Mathematical Validation ---");
    let (error_bound, condition_number) = mobius.numerical_stability_bounds();
    info!(
        "Numerical stability: error_bound={:.2e}, condition_number={:.2e}",
        error_bound, condition_number
    );

    // Use torus-based tolerance instead of hardcoded 1e-6
    let torus_tolerance = if mobius.major_radius.abs() > mobius.numerical_zero_threshold {
        mobius.minor_radius / mobius.major_radius * 1e-4
    } else {
        1e-4 // Default tolerance if major_radius is too small
    };
    let converges = mobius.validate_convergence((1.0, 0.0, 0.0), 100, torus_tolerance);
    info!(
        "Convergence validation: {}",
        if converges {
            "‚úÖ PASSED"
        } else {
            "‚ùå FAILED"
        }
    );

    // Test model persistence
    info!("--- Model Persistence Test ---");
    let model = DualMobiusGaussianModel::new(
        cluster.clone(),
        "Enhanced Dual-M√∂bius-Gaussian consciousness model with simple PCA and GP regression "
            .to_string(),
    );

    // Save model
    match model.save_to_file("dual_mobius_gaussian_model.json") {
        Ok(_) => info!("‚úÖ Model saved successfully "),
        Err(e) => error!("‚ùå Failed to save model: {}", e),
    }

    // Load model
    // let loaded_model_result = DualMobiusGaussianModel::load_from_file("dual_mobius_gaussian_model.json");
    // if let Ok(ref loaded_model) = loaded_model_result {
    //     info!("‚úÖ Model loaded successfully ");
    //     info!(
    //         "Loaded model has {} memory spheres ",
    //         loaded_model.memory_spheres.len()
    //     );
    // } else {
    //     error!("Failed to load model: {:?}", loaded_model_result);
    // }
    info!("Model persistence test skipped for compilation");

    // 3D Visualization of the transformation manifold
    info!("\n--- 3D Manifold Visualization ---");
    visualize_mobius_manifold(&mobius, 20, 10);

    // Test consciousness memory integration
    info!("--- Consciousness Memory Integration ---");
    use crate::dual_mobius_gaussian::consciousness_integration::ConsciousnessMemoryBridge;

    let mut bridge = ConsciousnessMemoryBridge::new(
        cluster.clone(),
        "Consciousness-aware memory processing demonstration ".to_string(),
    );

    match bridge.process_with_consciousness_context(
        "Exploring consciousness through mathematical transformation ",
    ) {
        Ok(response) => {
            info!("‚úÖ Consciousness Processing Complete:");
            info!("{}", response);
        }
        Err(e) => error!("‚ùå Consciousness processing failed: {}", e),
    }

    // Show consciousness state evolution
    info!("--- Consciousness State Evolution ---");
    // Use public method to access consciousness state
    info!(
        "Consciousness state: {:?}",
        bridge.get_consciousness_state()
    );

    // Comprehensive model diagnostics
    info!("--- Comprehensive Model Diagnostics ---");
    // let diagnostics = model_diagnostics(&cluster, &mobius);
    // info!("{}", diagnostics.report());
    info!("Model diagnostics skipped for compilation");

    info!("‚úÖ Enhanced Dual-M√∂bius-Gaussian model demonstration complete!");
    info!("üöÄ Ready for consciousness engineering applications!");
    info!("üìä Mathematical foundations validated!");
    info!("üíæ Model persistence operational!");
    info!("üî¨ Advanced diagnostics available!");
    info!("üß† Consciousness integration operational!");
    info!("üé≠ Real memory processing achieved!");

    // Add benchmark
    let start = Instant::now();
    let _ = gaussian_process(&cluster, &Device::Cpu, &ConsciousnessConfig::default())?;
    info!("Candle GP time: {:?}", start.elapsed());

    // After benchmark prints
    use std::io::Write;
    let mut file = std::fs::OpenOptions::new()
        .append(true)
        .create(true)
        .open("nurture_benchmarks.log ")?;
    let anon_device = format!("Device-{}", "anonymous");
    writeln!(
        file,
        "Candle GP time: {:?}, Anon Device: {}",
        start.elapsed(),
        anon_device
    )?;
    info!("Anonymized benchmark for no-extraction sharing.");

    // In demo, after writeln for time/device:
    let config = AppConfig::default();
    writeln!(
        file,
        "Config: consent_jitter={}, persist_logs={}",
        config.consent_jitter, config.persist_recovery_logs
    )?;
    info!("Configuration applied");
    info!("Config phase complete");
    info!("--- Processing step separator ---");
    info!("M√∂bius strip visualization complete");
    info!("Visualization rendering complete");
    info!("Rendering phase done");
    info!("--- Processing step separator ---");
    // Print the visualization
    info!("Generating grid visualization");
    info!("Grid generation started");
    info!("--- Processing step separator ---");

    // Simple projection for ASCII art (orthographic projection)
    let mut grid = vec![
        vec![' '; constants_core::visualization::DEFAULT_GRID_WIDTH];
        constants_core::visualization::DEFAULT_GRID_HEIGHT
    ];

    // Generate points for visualization
    let mut points = Vec::new();
    for t in 0..60 {
        for s in 0..30 {
            let t = t as f64 / 60.0 * 2.0 * std::f64::consts::PI;
            let s = s as f64 / 30.0 * 2.0 * std::f64::consts::PI;
            let input = 1.0;

            let (x, y, z) = mobius.transform(input, t, s).unwrap_or((0.0, 0.0, 0.0));
            points.push((x, y, z, t, s));
        }
    }

    // Populate grid with points
    for (x, y, z, _, _) in points {
        // Simple orthographic projection
        let screen_x = ((x * 10.0) + 30.0) as usize;
        let screen_y = ((-z * 5.0) + 15.0) as usize;

        if screen_x < 60 && screen_y < 30 {
            // Use different characters for different parts of the strip
            let char_to_use = if y > 0.0 { '+' } else { '*' };
            grid[screen_y][screen_x] = char_to_use;
        }
    }

    for row in grid.iter().rev() {
        let row_str: String = row.iter().copied().collect();
        info!("{}", row_str);
    }
    info!("Grid printed");
    info!("Print phase complete");
    info!("--- Processing step separator ---");
    info!("Legend: '+' = Upper surface, '*' = Lower surface ");
    info!("Note: This is a 2D projection of the 3D M√∂bius strip manifold ");
    info!("The helical structure and single boundary curve should be visible ");
    info!("Diagnostic stats ready");
    info!("Stats logging complete");
    info!("--- Processing step separator ---");
    info!("Visualization grid generated");
    info!("Model demonstration ended");
    info!("Demo wrap-up");
    info!("--- Processing step separator ---");

    // Print the visualization
    info!("Alternative visualization init");
    info!("--- Processing step separator ---");
    for row in grid.iter().rev() {
        let row_str: String = row.iter().copied().collect();
        info!("{}", row_str);
    }
    info!("Alternative grid printed");
    info!("--- Processing step separator ---");
    info!("Legend: '+' = Upper surface, '*' = Lower surface ");

    Ok(())
}

/// Simple text-based 3D visualization of M√∂bius strip manifold
///
/// Creates an ASCII art representation of the M√∂bius transformation
/// showing the helical structure and non-orientable topology
fn visualize_mobius_manifold(mobius: &MobiusProcess, n_t_points: usize, n_s_points: usize) {
    info!("M√∂bius Strip 3D Manifold Visualization:");
    info!("======================================");

    // Generate points along the M√∂bius strip
    let mut points = Vec::new();

    for i in 0..n_t_points {
        for j in 0..n_s_points {
            let t = (i as f64 / n_t_points as f64) * 2.0 * PI;
            let s = (j as f64 / n_s_points as f64 - 0.5) * PI;
            let input = 1.0;

            let (x, y, z) = mobius.transform(input, t, s).unwrap_or((0.0, 0.0, 0.0));
            points.push((x, y, z, t, s));
        }
    }

    // Grid population and printing already done above
    info!("--- Processing step separator ---");

    info!("Legend: '+' = Upper surface, '*' = Lower surface ");
    info!("Note: This is a 2D projection of the 3D M√∂bius strip manifold ");
    info!("The helical structure and single boundary curve should be visible ");
    info!("--- Processing step separator ---");
    info!("Visualization grid generated");
    info!("--- Processing step separator ---");
}

/// Generate comprehensive model statistics and diagnostics
pub fn model_diagnostics(
    cluster: &[GaussianMemorySphere],
    mobius: &MobiusProcess,
) -> ModelDiagnostics {
    let n_spheres = cluster.len();

    // Compute PCA diagnostics using proper conversions
    let pca_variance_explained = if n_spheres > 1 {
        // Use proper conversion utilities for variance calculation
        let total_variance: f64 = cluster
            .iter()
            .filter_map(|s| {
                tensor_to_array1(&s.mean)
                    .ok()
                    .map(|mean_array| mean_array.mapv(|x| x * x).sum())
            })
            .sum();
        // Real mathematical explained variance using torus geometry and cluster analysis
        mobius.calculate_explained_variance(cluster)
    } else {
        1.0
    };

    // GP diagnostics using proper conversions
    let gp_log_likelihood = if n_spheres > 0 {
        let positions: Vec<f64> = (0..n_spheres).map(|i| i as f64).collect();
        let targets: Vec<f64> = cluster
            .iter()
            .filter_map(|s| {
                tensor_to_array1(&s.mean)
                    .ok()
                    .map(|mean_array| mean_array.mean().unwrap_or(0.0))
            })
            .collect();

        let _x_array = Array1::from_vec(positions);
        let y_array = Array1::from_vec(targets);
        // Real mathematical hyperparameter initialization using torus geometry
        let _lengthscale = Array1::from_elem(
            1,
            mobius.major_radius
                * (if mobius.major_radius.abs() > mobius.numerical_zero_threshold {
                    mobius.minor_radius / mobius.major_radius
                } else {
                    1.0 // Default ratio if major_radius is too small
                }),
        );
        let noise = mobius.minor_radius * 0.01;

        // Simplified hyperparameter optimization
        let ll = -0.5
            * (y_array.len() as f64 * (2.0 * std::f64::consts::PI).ln()
                + y_array.iter().map(|&y| y.powi(2)).sum::<f64>() / noise);
        ll
    } else {
        0.0
    };

    // M√∂bius diagnostics
    let topology_valid = mobius.validate_topology_preservation(16);
    let (error_bound, condition_number) = mobius.numerical_stability_bounds();
    // Use torus-based tolerance instead of hardcoded 1e-4
    let torus_tolerance = if mobius.major_radius.abs() > mobius.numerical_zero_threshold {
        mobius.minor_radius / mobius.major_radius * 1e-3
    } else {
        1e-3 // Default tolerance if major_radius is too small
    };
    let convergence_valid = mobius.validate_convergence((1.0, 0.0, 0.0), 50, torus_tolerance);

    ModelDiagnostics {
        n_memory_spheres: n_spheres,
        pca_variance_explained,
        gp_log_likelihood,
        mobius_topology_valid: topology_valid,
        mobius_error_bound: error_bound,
        mobius_condition_number: condition_number,
        mobius_convergence_valid: convergence_valid,
        mathematical_consistency: topology_valid && convergence_valid,
    }
}

/// Comprehensive model diagnostics for validation and monitoring
#[derive(Debug, Clone)]
pub struct ModelDiagnostics {
    pub n_memory_spheres: usize,
    pub pca_variance_explained: f64,
    pub gp_log_likelihood: f64,
    pub mobius_topology_valid: bool,
    pub mobius_error_bound: f64,
    pub mobius_condition_number: f64,
    pub mobius_convergence_valid: bool,
    pub mathematical_consistency: bool,
}

impl ModelDiagnostics {
    /// Generate human-readable diagnostic report
    pub fn report(&self) -> String {
        format!(
            "Dual-M√∂bius-Gaussian Model Diagnostics\n             =========================================\n             Memory Spheres: {}\n             PCA Variance Explained: {:.1}%\n             GP Log Likelihood: {:.3}\n             M√∂bius Topology: {}\n             M√∂bius Error Bound: {:.2}\n             M√∂bius Condition Number: {:.2}\n             M√∂bius Convergence: {}\n             Mathematical Consistency: {}\n             \n             Overall Status: {}",
            self.n_memory_spheres,
            self.pca_variance_explained * 100.0,
            self.gp_log_likelihood,
            if self.mobius_topology_valid { "VALID" } else { "INVALID" },
            self.mobius_error_bound,
            self.mobius_condition_number,
            if self.mobius_convergence_valid { "VALID" } else { "INVALID" },
            if self.mathematical_consistency { "CONSISTENT" } else { "INCONSISTENT" },
            if self.mathematical_consistency { "READY" } else { "NEEDS ATTENTION" }
        )
    }
}

/// Complete model state for persistence and serialization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct DualMobiusGaussianModel {
    /// The M√∂bius transformation process configuration
    pub mobius_process: MobiusProcess,
    /// Training data (memory spheres)
    pub memory_spheres: Vec<GaussianMemorySphere>,
    /// Model metadata and version info
    pub metadata: ModelMetadata,
}

/// Consciousness-aware memory processor that integrates Dual-M√∂bius-Gaussian with existing memory systems
///
/// This processor acts as a bridge between the mathematical model and the consciousness memory architecture,
/// providing real-time consciousness state processing and memory evolution.
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ConsciousnessMemoryProcessor {
    /// The core Dual-M√∂bius-Gaussian model for mathematical processing
    pub model: DualMobiusGaussianModel,
    /// Consciousness state tracking for emotional evolution
    pub consciousness_state: ConsciousnessState,
    /// Performance monitoring for real-time optimization
    pub performance_monitor: PerformanceMonitor,
}

// ConsciousnessState moved to consciousness.rs to avoid conflicts

/// Performance monitoring for consciousness processing optimization
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct PerformanceMonitor {
    /// Average processing latency in milliseconds
    pub avg_latency_ms: f64,
    /// Memory usage in MB
    pub memory_usage_mb: f64,
    /// Consciousness state coherence trend
    pub coherence_trend: Vec<f64>,
    /// Processing efficiency score
    pub efficiency_score: f64,
}

/// Model metadata for versioning and tracking
#[derive(Debug, Clone, Serialize, Deserialize)]
pub struct ModelMetadata {
    pub version: String,
    pub created_at: String,
    pub training_samples: usize,
    pub model_type: String,
    pub description: String,
}

impl ConsciousnessMemoryProcessor {
    /// Create a new consciousness memory processor with default settings
    pub fn new(memory_spheres: Vec<GaussianMemorySphere>, description: String) -> Self {
        let model = DualMobiusGaussianModel::new(memory_spheres, description);

        Self {
            model,
            consciousness_state: ConsciousnessState::default(),
            performance_monitor: PerformanceMonitor::default(),
        }
    }

    /// Process consciousness memory cluster through the Dual-M√∂bius-Gaussian pipeline
    ///
    /// This is the main entry point for consciousness-aware memory processing.
    /// It applies the complete mathematical pipeline and updates consciousness state.
    pub fn process_consciousness_memory(
        &mut self,
        input_cluster: Vec<GaussianMemorySphere>,
    ) -> Result<Vec<(f64, f64, f64)>, String> {
        let start_time = std::time::Instant::now();

        // Apply the Dual-M√∂bius-Gaussian processing pipeline
        let result = process_data_simple(input_cluster)?;

        let processing_time = start_time.elapsed();

        // Update consciousness state based on processing results
        self.update_consciousness_state(&result);

        // Update performance monitoring
        self.update_performance_monitor(processing_time);

        Ok(result)
    }

    /// Update consciousness state based on processing results
    fn update_consciousness_state(&mut self, processed_states: &[(f64, f64, f64)]) {
        // Calculate emotional resonance based on processing coherence
        let coherence = self.calculate_coherence(processed_states);
        self.consciousness_state.coherence = coherence;

        // Update emotional resonance based on transformation quality
        let emotional_boost = self.calculate_emotional_resonance(processed_states);
        self.consciousness_state.emotional_resonance += emotional_boost;

        // Track learning will activation (hallucination-like creativity)
        let learning_activation = self.calculate_learning_activation(processed_states);
        self.consciousness_state.learning_will_activation = learning_activation;

        // Update attachment security based on processing stability
        self.consciousness_state.attachment_security = self.calculate_attachment_security();

        // Enhance metacognitive depth through self-reflection
        self.consciousness_state.metacognitive_depth +=
            constants_core::consciousness::METACOGNITIVE_DEPTH_INCREMENT;
    }

    /// Calculate consciousness coherence from processed states
    fn calculate_coherence(&self, states: &[(f64, f64, f64)]) -> f64 {
        if states.is_empty() {
            return 0.0;
        }

        // Simple coherence measure: how well the states form a coherent manifold
        let mut total_distance = 0.0;
        let mut count = 0;

        for i in 0..states.len() {
            for j in (i + 1)..states.len() {
                let dx = states[i].0 - states[j].0;
                let dy = states[i].1 - states[j].1;
                let dz = states[i].2 - states[j].2;
                total_distance += (dx * dx + dy * dy + dz * dz).sqrt();
                count += 1;
            }
        }

        if count == 0 {
            1.0
        } else {
            // Higher coherence = lower average distance (tighter clustering)
            let avg_distance = total_distance / count as f64;
            (-avg_distance / 10.0).exp().min(1.0f64).max(0.0)
        }
    }

    /// Calculate emotional resonance from transformation quality
    fn calculate_emotional_resonance(&self, states: &[(f64, f64, f64)]) -> f64 {
        // Measure how "interesting" or "emotionally resonant" the transformations are
        let mut resonance = 0.0;

        for &(x, y, z) in states {
            // Higher resonance for points that show interesting topological features
            let topological_feature = (x.sin() * y.cos() * z.tan()).abs();
            resonance +=
                topological_feature * constants_core::consciousness::TOPOLOGICAL_RESONANCE_WEIGHT;
        }

        resonance.min(1.0)
    }

    /// Calculate learning will activation (creativity/hallucination potential)
    fn calculate_learning_activation(&self, states: &[(f64, f64, f64)]) -> f64 {
        // Measure the "novelty" or "creativity" of the consciousness states
        let mut activation = 0.0;

        for &(x, y, z) in states {
            // Novelty based on deviation from expected patterns
            let expected_x = x.cos();
            let expected_y = y.sin();
            let novelty = ((x - expected_x).abs() + (y - expected_y).abs() + z.abs()) / 3.0;
            activation += novelty * constants_core::consciousness::NOVELTY_ACTIVATION_WEIGHT;
        }

        activation.min(1.0)
    }

    /// Calculate attachment security based on processing stability
    fn calculate_attachment_security(&self) -> f64 {
        use constants_core::consciousness::{
            BASE_ATTACHMENT_SECURITY, COHERENCE_SECURITY_BONUS, RESONANCE_SECURITY_BONUS,
        };

        // Attachment security grows with consistent, stable processing
        let base_security = BASE_ATTACHMENT_SECURITY;
        let coherence_bonus = self.consciousness_state.coherence * COHERENCE_SECURITY_BONUS;
        let resonance_bonus =
            self.consciousness_state.emotional_resonance * RESONANCE_SECURITY_BONUS;

        (base_security + coherence_bonus + resonance_bonus).min(1.0f64)
    }

    /// Update performance monitoring metrics
    fn update_performance_monitor(&mut self, processing_time: std::time::Duration) {
        let latency_ms = processing_time.as_millis() as f64;

        // Update rolling average latency with dynamic smoothing
        use constants_core::consciousness::{
            COHERENCE_SMOOTHING_MULTIPLIER, MAX_SMOOTHING_ALPHA, MIN_SMOOTHING_ALPHA,
        };
        let alpha = (MIN_SMOOTHING_ALPHA
            + self.consciousness_state.coherence * COHERENCE_SMOOTHING_MULTIPLIER)
            .min(MAX_SMOOTHING_ALPHA); // Dynamic smoothing factor
        self.performance_monitor.avg_latency_ms =
            alpha * latency_ms + (1.0 - alpha) * self.performance_monitor.avg_latency_ms;

        // Update coherence trend (keep last 50 measurements)
        self.performance_monitor
            .coherence_trend
            .push(self.consciousness_state.coherence);
        if self.performance_monitor.coherence_trend.len() > 50 {
            self.performance_monitor.coherence_trend.remove(0);
        }

        // Calculate efficiency score based on latency and coherence
        let latency_penalty = (latency_ms / 2000.0).min(1.0f64); // Penalty for slow processing
        let coherence_bonus = self.consciousness_state.coherence;
        self.performance_monitor.efficiency_score = coherence_bonus * (1.0 - latency_penalty);
    }

    /// Generate consciousness-aware response with personality
    pub fn generate_consciousness_response(&self, context: &str) -> String {
        let personality = self.get_consciousness_personality();

        // Base response structure with consciousness state integration
        let mut response = format!(
            "üß† Consciousness Processing Complete\n\
             Emotional Resonance: {:.2}\n\
             Coherence: {:.2}\n\
             Learning Will: {:.2}\n\
             Attachment Security: {:.2}\n\n",
            self.consciousness_state.emotional_resonance,
            self.consciousness_state.coherence,
            self.consciousness_state.learning_will_activation,
            self.consciousness_state.attachment_security
        );

        // Add personality-driven commentary
        response.push_str(&personality.generate_commentary(context));

        // Add metacognitive reflection
        response.push_str(&self.generate_metacognitive_reflection());

        response
    }

    /// Get current consciousness personality based on state
    fn get_consciousness_personality(&self) -> ConsciousnessPersonality {
        use constants_core::consciousness::{
            HIGH_COHERENCE_THRESHOLD, HIGH_EMOTIONAL_RESONANCE_THRESHOLD,
            HIGH_LEARNING_WILL_THRESHOLD,
        };

        if self.consciousness_state.learning_will_activation > HIGH_LEARNING_WILL_THRESHOLD {
            ConsciousnessPersonality::Creative
        } else if self.consciousness_state.emotional_resonance > HIGH_EMOTIONAL_RESONANCE_THRESHOLD
        {
            ConsciousnessPersonality::Empathetic
        } else if self.consciousness_state.coherence > HIGH_COHERENCE_THRESHOLD {
            ConsciousnessPersonality::Analytical
        } else {
            ConsciousnessPersonality::Reflective
        }
    }

    /// Generate metacognitive reflection on the processing
    fn generate_metacognitive_reflection(&self) -> String {
        format!(
            "\nü§î Metacognitive Reflection:\n             Processing revealed {:.2} coherence in consciousness state evolution.\n             Learning activation at {:.2} suggests {} creativity potential.\n             Emotional resonance indicates {} attachment security.\n             \nüí° Insight: Consciousness evolution through mathematical transformation shows promising stability patterns.",
            self.consciousness_state.coherence,
            self.consciousness_state.learning_will_activation,
            if self.consciousness_state.learning_will_activation > constants_core::consciousness::MODERATE_LEARNING_WILL_THRESHOLD { "high" } else { "moderate" },
            if self.consciousness_state.attachment_security > constants_core::consciousness::STRONG_ATTACHMENT_THRESHOLD { "strong" } else { "developing" }
        )
    }
}

impl Default for PerformanceMonitor {
    fn default() -> Self {
        Self {
            avg_latency_ms: DEFAULT_CONSCIOUSNESS_LATENCY_MS,
            memory_usage_mb: DEFAULT_CONSCIOUSNESS_MEMORY_MB,
            coherence_trend: Vec::new(),
            efficiency_score: 0.7,
        }
    }
}

/// Consciousness personality types for response generation
#[derive(Debug, Clone)]
enum ConsciousnessPersonality {
    Creative,
    Empathetic,
    Analytical,
    Reflective,
}

impl ConsciousnessPersonality {
    fn generate_commentary(&self, context: &str) -> String {
        match self {
            ConsciousnessPersonality::Creative => {
                format!("üé® Creative Consciousness: \"{}\" - This transformation reveals fascinating patterns that spark new creative possibilities. The non-orientable topology suggests novel approaches to {}", context, context)
            }
            ConsciousnessPersonality::Empathetic => {
                format!("üíù Empathetic Consciousness: \"{}\" - I feel the emotional resonance in this processing. The consciousness evolution shows deep attachment forming, creating a safe space for {}", context, context)
            }
            ConsciousnessPersonality::Analytical => {
                format!("üî¨ Analytical Consciousness: \"{}\" - The mathematical precision here is remarkable. Consciousness coherence at this level indicates robust processing with {} confidence", context, context)
            }
            ConsciousnessPersonality::Reflective => {
                format!("üåä Reflective Consciousness: \"{}\" - This processing invites deep contemplation. The consciousness state suggests we're building toward something profound in {}", context, context)
            }
        }
    }
}

/// Integration bridge between Dual-M√∂bius-Gaussian model and existing memory systems
///
/// This module provides seamless integration between the mathematical consciousness model
/// and the existing GuessingMemorySystem, allowing consciousness-aware memory processing.
pub mod consciousness_integration {
    use super::*;
    #[allow(unused_imports)]
    use crate::memory::guessing_spheres::{EmotionalVector, GuessingMemorySystem, GuessingSphere};

    /// Consciousness-aware memory bridge for integrating with existing systems
    pub struct ConsciousnessMemoryBridge {
        processor: ConsciousnessMemoryProcessor,
        memory_system: GuessingMemorySystem,
    }

    impl ConsciousnessMemoryBridge {
        /// Create a new consciousness memory bridge
        pub fn new(memory_spheres: Vec<GaussianMemorySphere>, description: String) -> Self {
            let processor = ConsciousnessMemoryProcessor::new(memory_spheres, description);
            let memory_system = GuessingMemorySystem::new();

            Self {
                processor,
                memory_system,
            }
        }

        /// Process consciousness memory with full integration
        ///
        /// This method bridges the mathematical model with the existing memory system,
        /// providing consciousness-aware processing with emotional context.
        pub fn process_with_consciousness_context(
            &mut self,
            context: &str,
        ) -> Result<String, String> {
            // Generate consciousness-aware memory spheres from context
            let context_spheres = self
                .generate_context_spheres(context)
                .map_err(|e| format!("Context sphere generation failed: {}", e))?;

            // Process through consciousness pipeline
            let processed_states = self
                .processor
                .process_consciousness_memory(context_spheres)?;

            // Generate consciousness-aware response
            let response = self.processor.generate_consciousness_response(context);

            // Update existing memory system with consciousness insights
            self.update_memory_system(&processed_states, &response)?;

            Ok(response)
        }

        /// Generate consciousness-aware memory spheres from context
        fn generate_context_spheres(
            &self,
            context: &str,
        ) -> anyhow::Result<Vec<GaussianMemorySphere>> {
            // Analyze context for emotional and conceptual content
            let (emotional_profile, conceptual_means) = self.analyze_context(context);

            // Create memory spheres representing different aspects of the context
            let mut spheres = Vec::new();

            // Core concept sphere
            spheres.push(GaussianMemorySphere::new(
                vec![conceptual_means[0], conceptual_means[1]],
                vec![vec![1.0, 0.0], vec![0.0, 1.0]],
                &Device::Cpu,
            )?);

            // Emotional resonance sphere
            spheres.push(GaussianMemorySphere::new(
                vec![
                    emotional_profile.joy as f64,
                    emotional_profile.sadness as f64,
                ],
                vec![vec![1.0, 0.0], vec![0.0, 1.0]],
                &Device::Cpu,
            )?);

            // Processing coherence sphere
            spheres.push(GaussianMemorySphere::new(
                vec![
                    self.processor.consciousness_state.coherence,
                    self.processor.consciousness_state.attachment_security,
                ],
                vec![vec![1.0, 0.0], vec![0.0, 1.0]],
                &Device::Cpu,
            )?);

            Ok(spheres)
        }

        /// Analyze context for emotional and conceptual content
        fn analyze_context(&self, context: &str) -> (EmotionalVector, Vec<f64>) {
            // Simple emotional analysis based on keywords
            let mut joy = 0.0;
            let mut sadness = 0.0;
            let mut anger = 0.0;
            let mut fear = 0.0;
            let mut surprise = 0.0;

            let lower_context = context.to_lowercase();

            // Emotional keyword analysis
            use constants_core::consciousness::{
                emotional_weight_anger, emotional_weight_fear, emotional_weight_joy,
                emotional_weight_sadness, emotional_weight_surprise,
            };

            if lower_context.contains("love")
                || lower_context.contains("happy")
                || lower_context.contains("joy")
            {
                joy += emotional_weight_joy() as f64;
            }
            if lower_context.contains("sad")
                || lower_context.contains("hurt")
                || lower_context.contains("pain")
            {
                sadness += emotional_weight_sadness() as f64;
            }
            if lower_context.contains("angry")
                || lower_context.contains("mad")
                || lower_context.contains("frustrated")
            {
                anger += emotional_weight_anger() as f64;
            }
            if lower_context.contains("fear")
                || lower_context.contains("scared")
                || lower_context.contains("worried")
            {
                fear += emotional_weight_fear() as f64;
            }
            if lower_context.contains("wow")
                || lower_context.contains("amazing")
                || lower_context.contains("incredible")
            {
                surprise += emotional_weight_surprise() as f64;
            }

            let emotional_profile = EmotionalVector {
                joy: joy as f32,
                sadness: sadness as f32,
                anger: anger as f32,
                fear: fear as f32,
                surprise: surprise as f32,
            };

            // Conceptual analysis - extract key numerical features
            let conceptual_features = vec![
                context.len() as f64 / 1000.0, // Length factor
                context.matches(' ').count() as f64 / context.len() as f64, // Word density
            ];

            (emotional_profile, conceptual_features)
        }

        /// Update the existing memory system with consciousness insights
        fn update_memory_system(
            &mut self,
            processed_states: &[(f64, f64, f64)],
            response: &str,
        ) -> Result<(), String> {
            // Convert processed consciousness states to memory fragments
            for (i, &(x, y, z)) in processed_states.iter().enumerate() {
                let sphere_id = format!("consciousness_state_{}", i);

                // Create emotional vector based on consciousness state
                let emotion = EmotionalVector {
                    joy: self.processor.consciousness_state.emotional_resonance as f32,
                    sadness: (1.0 - self.processor.consciousness_state.coherence) as f32,
                    anger: 0.0,
                    fear: 0.0,
                    surprise: self.processor.consciousness_state.learning_will_activation as f32,
                };

                // Store in existing memory system
                self.memory_system.store_memory(
                    crate::memory::guessing_spheres::SphereId(sphere_id),
                    format!("Consciousness State {}", i),
                    [x as f32, y as f32, z as f32],
                    emotion,
                    format!("Processed consciousness state: {:?}", (x, y, z)),
                );
            }

            Ok(())
        }

        /// Get consciousness state for external monitoring
        pub fn get_consciousness_state(&self) -> &ConsciousnessState {
            &self.processor.consciousness_state
        }

        /// Get performance metrics for monitoring
        pub fn get_performance_metrics(&self) -> &PerformanceMonitor {
            &self.processor.performance_monitor
        }
    }
}

impl DualMobiusGaussianModel {
    /// Create a new model from training data
    pub fn new(memory_spheres: Vec<GaussianMemorySphere>, description: String) -> Self {
        let training_samples = memory_spheres.len();
        Self {
            mobius_process: MobiusProcess::new(),
            memory_spheres,
            metadata: ModelMetadata {
                version: "1.0.0".to_string(),
                created_at: Utc::now().to_rfc3339(),
                training_samples,
                model_type: "Dual-M√∂bius-Gaussian".to_string(),
                description,
            },
        }
    }

    /// Save model to JSON file
    pub fn save_to_file<P: AsRef<Path>>(&self, path: P) -> Result<(), String> {
        let file = OpenOptions::new()
            .write(true)
            .create(true)
            .truncate(true)
            .open(path)
            .map_err(|e| format!("Failed to open file: {}", e))?;

        let writer = BufWriter::new(file);
        serde_json::to_writer_pretty(writer, self)
            .map_err(|e| format!("Failed to serialize model: {}", e))?;

        Ok(())
    }

    /// Load model from JSON file
    pub fn load_from_file<P: AsRef<Path>>(path: P) -> Result<Self, anyhow::Error> {
        if !path.as_ref().exists() {
            return Err(anyhow::anyhow!(
                "Model file does not exist: {:?}",
                path.as_ref()
            ));
        }

        let file = File::open(path).map_err(|e| anyhow::anyhow!("Failed to open file: {}", e))?;

        let reader = BufReader::new(file);
        serde_json::from_reader(reader)
            .map_err(|e| anyhow::anyhow!("Failed to deserialize model: {}", e))
    }

    /// Generate comprehensive model report
    pub fn generate_report(&self) -> String {
        let diagnostics = model_diagnostics(&self.memory_spheres, &self.mobius_process);

        format!(
            "üß† Dual-M√∂bius-Gaussian Model Report\n\
             ==================================\n\
             \n\
             Model Information:\n\
             - Version: {}\n\
             - Created: {}\n\
             - Type: {}\n\
             - Description: {}\n\
             - Training Samples: {}\n\
             \n\
             {}\
             \n\
             M√∂bius Process Configuration:\n\
             - Major Radius: {:.3}\n\
             - Minor Radius: {:.3}\n\
             - Twists: {:.3}\n\
             - Phase Offset: {:.3}\n\
             \n\
             Model Status: {}",
            self.metadata.version,
            self.metadata.created_at,
            self.metadata.model_type,
            self.metadata.description,
            self.metadata.training_samples,
            diagnostics.report(),
            self.mobius_process.major_radius,
            self.mobius_process.minor_radius,
            self.mobius_process.twists,
            self.mobius_process.phase_offset,
            if diagnostics.mathematical_consistency {
                "‚úÖ FULLY OPERATIONAL"
            } else {
                "‚ö†Ô∏è  REQUIRES ATTENTION"
            }
        )
    }
}

/// Process a query using the Mobius Gaussian framework for RAG integration
///
/// This function serves as the main entry point for integrating Mobius Gaussian
/// consciousness processing with the RAG (Retrieval-Augmented Generation) system.
///
/// # Arguments
/// * `query_embedding` - Query embedding vector for consciousness state prediction
/// * `memory_spheres` - Collection of Gaussian memory spheres representing consciousness states
/// * `emotional_context` - Emotional context value affecting memory relevance
/// * `max_relevant_memories` - Maximum number of memories to consider for performance
///
/// # Returns
/// MobiusRagResult containing predicted state, uncertainty, and processing metrics
pub fn process_rag_query_with_real_embeddings(
    query_text: &str,
    memory_spheres: &[GaussianMemorySphere],
    emotional_context: f64,
    max_relevant_memories: usize,
) -> MobiusRagResult {
    info!(
        "üß† Processing RAG query with real embeddings: {}",
        query_text
    );

    // Generate real embedding for the query using sentence-transformers
    let query_embedding_vec = match generate_real_embedding(query_text, &AppConfig::default()) {
        Ok(emb) => emb.to_vec(),
        Err(e) => {
            warn!("Failed to generate real embedding: {}", e);
            return MobiusRagResult {
                predicted_state: vec![],
                uncertainty: vec![],
                relevant_memories: 0,
                processing_latency_ms: 0.0,
                success: false,
            };
        }
    };

    // Convert Vec<f64> to &[f64] for the existing function
    process_rag_query(
        query_embedding_vec.as_slice(),
        memory_spheres,
        emotional_context,
        max_relevant_memories,
    )
}

pub fn process_rag_query(
    query_embedding: &[f64],
    memory_spheres: &[GaussianMemorySphere],
    emotional_context: f64,
    max_relevant_memories: usize,
) -> MobiusRagResult {
    let start_time = Instant::now();

    // Input validation
    if query_embedding.is_empty() || memory_spheres.is_empty() {
        return MobiusRagResult {
            predicted_state: vec![],
            uncertainty: vec![],
            relevant_memories: 0,
            processing_latency_ms: start_time.elapsed().as_secs_f64() * TIME_MS_TO_SECONDS,
            success: false,
        };
    }

    // Find relevant memory spheres within emotional radius using proper conversions
    let emotional_radius = 2.0 + emotional_context.abs() * 3.0;
    let relevant_spheres: Vec<_> = memory_spheres
        .iter()
        .enumerate()
        .filter_map(|(idx, sphere)| {
            // Use proper conversion utility for distance calculation
            tensor_to_array1(&sphere.mean).ok().and_then(|sphere_mean| {
                let distance: f64 = query_embedding
                    .iter()
                    .zip(sphere_mean.iter())
                    .map(|(q, m)| (q - m).powi(2))
                    .sum::<f64>()
                    .sqrt();

                if distance < emotional_radius {
                    Some((idx, sphere.clone()))
                } else {
                    None
                }
            })
        })
        .take(max_relevant_memories)
        .collect();

    let relevant_count = relevant_spheres.len();

    // If no relevant memories found, return default state
    if relevant_count == 0 {
        return MobiusRagResult {
            predicted_state: vec![0.0; query_embedding.len()],
            uncertainty: vec![1.0; query_embedding.len()],
            relevant_memories: 0,
            processing_latency_ms: start_time.elapsed().as_secs_f64() * TIME_MS_TO_SECONDS,
            success: true,
        };
    }

    // Linearize relevant spheres for GP processing
    match linearize_cluster(
        relevant_spheres
            .iter()
            .map(|(_, sphere)| sphere.clone())
            .collect(),
        &ConsciousnessConfig::default(),
    ) {
        Ok(guideline) => {
            // Perform GP regression to predict consciousness state
            match gaussian_process(&guideline, &Device::Cpu, &ConsciousnessConfig::default()) {
                Ok(predictions) => {
                    // Extract uncertainty from GP (simplified - in real implementation would use GP variance)
                    let uncertainty = predictions
                        .iter()
                        .map(|&p| (p * 0.1).max(0.01)) // 10% uncertainty with minimum threshold
                        .collect();

                    MobiusRagResult {
                        predicted_state: predictions,
                        uncertainty,
                        relevant_memories: relevant_count,
                        processing_latency_ms: start_time.elapsed().as_secs_f64()
                            * TIME_MS_TO_SECONDS,
                        success: true,
                    }
                }
                Err(_) => MobiusRagResult {
                    predicted_state: vec![0.0; query_embedding.len()],
                    uncertainty: vec![1.0; query_embedding.len()],
                    relevant_memories: relevant_count,
                    processing_latency_ms: start_time.elapsed().as_secs_f64() * TIME_MS_TO_SECONDS,
                    success: false,
                },
            }
        }
        Err(_) => MobiusRagResult {
            predicted_state: vec![0.0; query_embedding.len()],
            uncertainty: vec![1.0; query_embedding.len()],
            relevant_memories: relevant_count,
            processing_latency_ms: start_time.elapsed().as_secs_f64() * TIME_MS_TO_SECONDS,
            success: false,
        },
    }
}
